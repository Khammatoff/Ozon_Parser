import csv
import logging
import random
import time
import os
import sys
import tempfile
import shutil
import json
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium_stealth import stealth
from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.core.os_manager import ChromeType
import pika

# –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫–∏ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
os.makedirs("/app/logs", exist_ok=True)
os.makedirs("/app/data", exist_ok=True)
os.makedirs("/app/screenshots", exist_ok=True)
os.makedirs("/app/html", exist_ok=True)  # –î–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è HTML

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/app/logs/parser.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)


class OzonSellerParser:
    def __init__(self):
        self.instance_id = os.getenv('HOSTNAME', f"parser-{random.randint(1000, 9999)}")
        self.request_count = 0
        self.driver = None
        self.wait = None
        self.current_proxy = None
        self.proxy_list = []
        self.proxy_rotation_count = int(os.getenv('PROXY_ROTATION_COUNT', 3))
        self.proxy_timeout = int(os.getenv('PROXY_ROTATION_TIMEOUT', 30))

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏
        proxy_list_str = os.getenv('PROXY_LIST', '')
        if proxy_list_str:
            self.proxy_list = [p.strip() for p in proxy_list_str.split(',') if p.strip()]

        # –£–Ω–∏–∫–∞–ª—å–Ω–∞—è –≤—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è Chrome
        self.chrome_temp_dir = tempfile.mkdtemp()
        logging.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞ {self.instance_id}, –ø—Ä–æ—Ñ–∏–ª—å: {self.chrome_temp_dir}")

        try:
            self.setup_driver()
            self.wait = WebDriverWait(self.driver, 15)

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CSV
            self.data_dir = "/app/data"
            os.makedirs(self.data_dir, exist_ok=True)
            self.csv_file = f"{self.data_dir}/sellers_{self.instance_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            self.init_csv()
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä—Å–µ—Ä–∞: {e}", exc_info=True)
            self.close()
            raise

    def rotate_proxy(self):
        """–†–æ—Ç–∞—Ü–∏—è –ø—Ä–æ–∫—Å–∏ –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –¥—Ä–∞–π–≤–µ—Ä–∞"""
        if not self.proxy_list or len(self.proxy_list) <= 1:
            return False

        try:
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –ø—Ä–æ–∫—Å–∏ –ø–æ –∫—Ä—É–≥—É
            self.current_proxy_index = (self.current_proxy_index + 1) % len(self.proxy_list)
            new_proxy = self.proxy_list[self.current_proxy_index]

            old_proxy = self.current_proxy
            self.current_proxy = new_proxy
            self.requests_per_proxy = 0  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫

            logging.info(
                f"üîÑ –†–æ—Ç–∏—Ä—É–µ–º –ø—Ä–æ–∫—Å–∏ [{self.current_proxy_index + 1}/{len(self.proxy_list)}]: {old_proxy} -> {new_proxy}")

            # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º –¥—Ä–∞–π–≤–µ—Ä —Å –Ω–æ–≤—ã–º –ø—Ä–æ–∫—Å–∏
            if self.driver:
                self.driver.quit()
                time.sleep(2)

            self.setup_driver()
            self.wait = WebDriverWait(self.driver, 15)

            logging.info("‚úÖ –ü—Ä–æ–∫—Å–∏ —É—Å–ø–µ—à–Ω–æ —Å–º–µ–Ω–µ–Ω")
            return True

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–æ—Ç–∞—Ü–∏–∏ –ø—Ä–æ–∫—Å–∏: {e}")
            # –ü—Ä–æ–±—É–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–∞–±–æ—Ç—É —Å —Ç–µ–∫—É—â–∏–º –ø—Ä–æ–∫—Å–∏
            try:
                if self.driver:
                    self.driver.quit()
                self.setup_driver()
                self.wait = WebDriverWait(self.driver, 15)
            except:
                pass
            return False

    def setup_driver(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ Chrome –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ Docker —Å headless, stealth –∏ –ø—Ä–æ–∫—Å–∏"""
        chrome_options = Options()

        # === –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø—Ü–∏–∏ –¥–ª—è Docker ===
        chrome_options.add_argument("--headless=new")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--disable-extensions")
        chrome_options.add_argument("--disable-setuid-sandbox")
        chrome_options.add_argument("--disable-software-rasterizer")
        chrome_options.add_argument("--disable-ipc-flooding-protection")
        chrome_options.add_argument("--disable-background-timer-throttling")
        chrome_options.add_argument("--disable-backgrounding-occluded-windows")
        chrome_options.add_argument("--disable-renderer-backgrounding")
        chrome_options.add_argument("--disable-features=VizDisplayCompositor")

        # === –†–∞–∑–º–µ—Ä –æ–∫–Ω–∞ ===
        chrome_options.add_argument("--window-size=1366,768")

        # === –£–õ–£–ß–®–ï–ù–ù–ê–Ø –ù–ê–°–¢–†–û–ô–ö–ê –ü–†–û–ö–°–ò ===
        use_proxies = os.getenv('USE_PROXIES', 'false').lower() == 'true'
        proxy_list_str = os.getenv('PROXY_LIST', '')

        if use_proxies and proxy_list_str:
            self.proxy_list = [p.strip() for p in proxy_list_str.split(',') if p.strip()]

            if self.proxy_list:
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–Ω–¥–µ–∫—Å –ø—Ä–æ–∫—Å–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ
                if not hasattr(self, 'current_proxy_index'):
                    self.current_proxy_index = 0
                    self.requests_per_proxy = 0

                # –ë–µ—Ä–µ–º —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–∫—Å–∏ –ø–æ –∏–Ω–¥–µ–∫—Å—É (–∞ –Ω–µ —Å–ª—É—á–∞–π–Ω—ã–π)
                current_proxy = self.proxy_list[self.current_proxy_index]
                chrome_options.add_argument(f'--proxy-server={current_proxy}')
                self.current_proxy = current_proxy

                logging.info(
                    f"üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏ [{self.current_proxy_index + 1}/{len(self.proxy_list)}]: {current_proxy}")
            else:
                logging.warning("‚ö†Ô∏è PROXY_LIST –ø—É—Å—Ç–æ–π, —Ä–∞–±–æ—Ç–∞–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏")
                self.current_proxy = None
                self.proxy_list = []
        else:
            logging.info("üîå –ü—Ä–æ–∫—Å–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö")
            self.current_proxy = None
            self.proxy_list = []

        # === –£–ª—É—á—à–µ–Ω–Ω—ã–µ stealth –æ–ø—Ü–∏–∏ ===
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_argument("--disable-features=UserAgentClientHint")
        chrome_options.add_argument("--no-first-run")
        chrome_options.add_argument("--no-default-browser-check")
        chrome_options.add_argument("--disable-component-extensions-with-background-pages")
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation", "enable-logging"])
        chrome_options.add_experimental_option('useAutomationExtension', False)

        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å
        chrome_options.add_argument(f"--user-data-dir={self.chrome_temp_dir}")

        # –°–ª—É—á–∞–π–Ω—ã–π User-Agent –∏–∑ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞
        user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/121.0.0.0",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15"
        ]
        chrome_options.add_argument(f"--user-agent={random.choice(user_agents)}")

        # === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞ ===
        try:
            service = Service(ChromeDriverManager(chrome_type=ChromeType.GOOGLE).install())
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞: {e}", exc_info=True)
            raise

        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ selenium-stealth
        try:
            stealth(
                self.driver,
                languages=["ru-RU", "ru", "en-US", "en"],
                vendor="Google Inc.",
                platform="Win32",
                webgl_vendor="Intel Inc.",
                renderer="Intel Iris OpenGL Engine",
                fix_hairline=True,
                run_on_insecure_origins=False
            )
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è selenium-stealth: {e}")

    def init_csv(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CSV —Ñ–∞–π–ª–∞ —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏"""
        headers = [
            'URL', '–ù–∞–∑–≤–∞–Ω–∏–µ', '–†–µ–π—Ç–∏–Ω–≥', '–û—Ç–∑—ã–≤—ã', '–ó–∞–∫–∞–∑—ã',
            '–û–ø–∏—Å–∞–Ω–∏–µ', '–°—Å—ã–ª–∫–∞_–Ω–∞_–º–∞–≥–∞–∑–∏–Ω', 'Instance_ID',
            '–û–ì–†–ù', '–ò–ù–ù', '–ù–∞–∑–≤–∞–Ω–∏–µ_—é—Ä_–ª–∏—Ü–∞', '–í–µ–±-—Å–∞–π—Ç',
            '–ö–æ–ª-–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤_–Ω–∞_—Å—Ç—Ä–∞–Ω–∏—Ü–µ', '–û–±—â–µ–µ_–∫–æ–ª-–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤', '–°—Ä–æ–∫_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏',
            'Html_–ø—É—Ç—å', '–¢–æ–≤–∞—Ä—ã_JSON'
        ]
        try:
            with open(self.csv_file, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                writer.writerow(headers)
            logging.info(f"‚úÖ –°–æ–∑–¥–∞–Ω CSV —Ñ–∞–π–ª: {self.csv_file}")
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è CSV: {e}", exc_info=True)

    def save_to_csv(self, data):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ CSV"""
        try:
            with open(self.csv_file, 'a', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                writer.writerow([
                    data.get('URL', ''),
                    data.get('–ù–∞–∑–≤–∞–Ω–∏–µ', ''),
                    data.get('–†–µ–π—Ç–∏–Ω–≥', ''),
                    data.get('–û—Ç–∑—ã–≤—ã', ''),
                    data.get('–ó–∞–∫–∞–∑—ã', ''),
                    data.get('–û–ø–∏—Å–∞–Ω–∏–µ', ''),
                    data.get('–°—Å—ã–ª–∫–∞_–Ω–∞_–º–∞–≥–∞–∑–∏–Ω', ''),
                    self.instance_id,
                    data.get('–û–ì–†–ù', ''),
                    data.get('–ò–ù–ù', ''),
                    data.get('–ù–∞–∑–≤–∞–Ω–∏–µ_—é—Ä_–ª–∏—Ü–∞', ''),
                    data.get('–í–µ–±-—Å–∞–π—Ç', ''),
                    data.get('–ö–æ–ª-–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤_–Ω–∞_—Å—Ç—Ä–∞–Ω–∏—Ü–µ', ''),
                    data.get('–û–±—â–µ–µ_–∫–æ–ª-–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤', ''),
                    data.get('–°—Ä–æ–∫_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏', ''),
                    data.get('Html_–ø—É—Ç—å', ''),
                    data.get('–¢–æ–≤–∞—Ä—ã_JSON', '')
                ])
                f.flush()
                os.fsync(f.fileno())
            logging.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ CSV")
            return True
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ CSV: {e}", exc_info=True)
            return False

    def save_html_page(self, seller_id, prefix=""):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
        try:
            html_path = f"/app/html/{prefix}{seller_id}_{int(time.time())}.html"
            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(self.driver.page_source)
            return html_path
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å HTML: {e}")
            return ""

    def extract_products_from_main_page(self):
        try:
            logging.info("üõí –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Ç–æ–≤–∞—Ä–æ–≤ —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")

            # –û–∂–∏–¥–∞–µ–º –ø–æ—è–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ —Å —Ç–æ–≤–∞—Ä–∞–º–∏ - –ò–©–ï–ú –¢–û–ß–ù–´–ô –°–ï–õ–ï–ö–¢–û–†
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "div[data-widget='infiniteVirtualPagination']"))
            )

            # –ü—Ä–æ–∫—Ä—É—Ç–∫–∞
            last_height = self.driver.execute_script("return document.body.scrollHeight")
            scroll_attempts = 0
            while scroll_attempts < 3:
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(2)
                new_height = self.driver.execute_script("return document.body.scrollHeight")
                if new_height == last_height:
                    break
                last_height = new_height
                scroll_attempts += 1

            products = []

            # ‚ö° –û–°–ù–û–í–ù–û–ô –°–ï–õ–ï–ö–¢–û–† –î–õ–Ø –ö–ê–†–¢–û–ß–ï–ö –¢–û–í–ê–†–û–í ‚ö°
            # –ò—â–µ–º –í–°–ï –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –∫–ª–∞—Å—Å—É –∏ data-–∞—Ç—Ä–∏–±—É—Ç—É
            product_cards = self.driver.find_elements(By.CSS_SELECTOR, "div.tile-root[data-index]")

            logging.info(f"üì¶ –ù–∞–π–¥–µ–Ω–æ –∫–∞—Ä—Ç–æ—á–µ–∫ —Ç–æ–≤–∞—Ä–æ–≤: {len(product_cards)}")

            for card in product_cards[:20]:  # –ü–µ—Ä–≤—ã–µ 20 —Ç–æ–≤–∞—Ä–æ–≤
                try:
                    product_data = {}

                    # 1. –ù–ê–ó–í–ê–ù–ò–ï –¢–û–í–ê–†–ê - –∏—â–µ–º –≤ —Å—Å—ã–ª–∫–µ –∏–ª–∏ –≤ span
                    try:
                        # –í–∞—Ä–∏–∞–Ω—Ç 1: –ò—â–µ–º —Ç–µ–∫—Å—Ç –≤ —Å—Å—ã–ª–∫–µ
                        link_elem = card.find_element(By.CSS_SELECTOR, "a[href*='/product/']")
                        product_data['name'] = link_elem.get_attribute('textContent').strip()
                    except:
                        # –í–∞—Ä–∏–∞–Ω—Ç 2: –ò—â–µ–º –≤ span —Å —Ç–µ–∫—Å—Ç–æ–º
                        try:
                            spans = card.find_elements(By.CSS_SELECTOR, "span")
                            for span in spans:
                                text = span.text.strip()
                                if text and len(text) > 10:  # –ù–∞–∑–≤–∞–Ω–∏–µ –æ–±—ã—á–Ω–æ –¥–ª–∏–Ω–Ω–æ–µ
                                    product_data['name'] = text
                                    break
                        except:
                            product_data['name'] = ''

                    # 2. –¶–ï–ù–ê –¢–û–í–ê–†–ê - –∏—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å —Ü–µ–Ω–æ–π
                    try:
                        # –ò—â–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ "‚ÇΩ" –∏–ª–∏ —Ü–∏—Ñ—Ä—ã —Å —Å–∏–º–≤–æ–ª–∞–º–∏ –≤–∞–ª—é—Ç
                        price_selectors = [
                            "span[class*='price']",
                            "span[class*='money']",
                            "div[class*='price']",
                            "//span[contains(text(), '‚ÇΩ')]"
                        ]
                        for selector in price_selectors:
                            try:
                                if selector.startswith("//"):
                                    price_elems = card.find_elements(By.XPATH, selector)
                                else:
                                    price_elems = card.find_elements(By.CSS_SELECTOR, selector)

                                for elem in price_elems:
                                    text = elem.text.strip()
                                    if '‚ÇΩ' in text or any(char.isdigit() for char in text):
                                        product_data['price'] = text
                                        break
                                if product_data.get('price'):
                                    break
                            except:
                                continue
                    except:
                        product_data['price'] = ''

                    # 3. –°–°–´–õ–ö–ê –ù–ê –¢–û–í–ê–†
                    try:
                        link_elem = card.find_element(By.CSS_SELECTOR, "a[href*='/product/']")
                        product_data['link'] = "https://www.ozon.ru" + link_elem.get_attribute('href')
                    except:
                        product_data['link'] = ''

                    # 4. –†–ï–ô–¢–ò–ù–ì –¢–û–í–ê–†–ê (–µ—Å–ª–∏ –µ—Å—Ç—å)
                    try:
                        rating_selectors = [
                            "[class*='rating']",
                            "[class*='star']",
                            "//span[contains(@class, 'rating')]"
                        ]
                        for selector in rating_selectors:
                            try:
                                if selector.startswith("//"):
                                    rating_elem = card.find_element(By.XPATH, selector)
                                else:
                                    rating_elem = card.find_element(By.CSS_SELECTOR, selector)

                                if rating_elem.text.strip():
                                    product_data['rating'] = rating_elem.text.strip()
                                    break
                            except:
                                continue
                    except:
                        product_data['rating'] = ''

                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ
                    if product_data.get('name'):
                        products.append(product_data)

                except Exception as e:
                    logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–∞: {e}")
                    continue

            logging.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–ø–∞—Ä—Å–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(products)}")
            return products

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Ç–æ–≤–∞—Ä–æ–≤: {e}")
            return []

    def click_shop_button(self):
        """–ö–ª–∏–∫ –ø–æ –∫–Ω–æ–ø–∫–µ '–ú–∞–≥–∞–∑–∏–Ω' —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º–∏ –∏–∑ HTML"""
        try:
            logging.info("üõçÔ∏è –ò—â–µ–º –∫–Ω–æ–ø–∫—É '–ú–∞–≥–∞–∑–∏–Ω'...")

            # ‚ö° –°–ö–†–û–õ–õ–ò–ú –ö –í–ï–†–•–£ –ü–ï–†–ï–î –ü–û–ò–°–ö–û–ú
            self.driver.execute_script("window.scrollTo(0, 0);")
            time.sleep(2)

            # üî• –û–°–ù–û–í–ù–´–ï –°–ï–õ–ï–ö–¢–û–†–´ –ò–ó –í–ê–®–ï–ì–û HTML:
            shop_selectors = [
                # –°–µ–ª–µ–∫—Ç–æ—Ä—ã –∏–∑ –≤–∞—à–µ–≥–æ HTML
                "div[data-widget='sellertransparency'] a[href*='/seller/']",
                "div.m6h_19 a[href*='/seller/']",  # –ü–æ –∫–ª–∞—Å—Å—É –∏–∑ data-widget
                "div.hm7_19 a[href*='/seller/']",  # –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
                "div.hm8_19 a[href*='/seller/']",
                "div.b5_4_4-a0",  # –ö–Ω–æ–ø–∫–∞ —Å —Å—Ç–∏–ª—è–º–∏ –∏–∑ –≤–∞—à–µ–≥–æ HTML
                "div[style*='background: var'][style*='border-radius: 8px']",  # –ü–æ —Å—Ç–∏–ª—è–º

                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
                "//a[contains(@href, '/seller/') and contains(text(), '–ú–∞–≥–∞–∑–∏–Ω')]",
                "//button[contains(text(), '–ú–∞–≥–∞–∑–∏–Ω')]",
                "//div[contains(@class, 'shop')]//a[contains(@href, '/seller/')]"
            ]

            for selector in shop_selectors:
                try:
                    if selector.startswith("//"):
                        elements = self.driver.find_elements(By.XPATH, selector)
                    else:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    logging.info(f"üîé –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–µ–ª–µ–∫—Ç–æ—Ä: {selector}, –Ω–∞–π–¥–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(elements)}")

                    for element in elements:
                        try:
                            if element.is_displayed() and element.is_enabled():
                                # –ü–æ–ª—É—á–∞–µ–º URL –ø–µ—Ä–µ–¥ –∫–ª–∏–∫–æ–º
                                shop_url = element.get_attribute('href')
                                element_text = element.text.strip()

                                logging.info(f"üéØ –ù–∞—à–ª–∏ –∫–Ω–æ–ø–∫—É –º–∞–≥–∞–∑–∏–Ω–∞: '{element_text}', URL: {shop_url}")

                                # –°–∫—Ä–æ–ª–ª–∏–º –∫ —ç–ª–µ–º–µ–Ω—Ç—É –∏ –∫–ª–∏–∫–∞–µ–º
                                self.driver.execute_script(
                                    "arguments[0].scrollIntoView({block: 'center', behavior: 'smooth'});", element)
                                time.sleep(2)

                                # –ö–ª–∏–∫–∞–µ–º —á–µ—Ä–µ–∑ JavaScript (–Ω–∞–¥–µ–∂–Ω–µ–µ)
                                self.driver.execute_script("arguments[0].click();", element)

                                # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–æ–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                                time.sleep(random.uniform(3, 5))
                                WebDriverWait(self.driver, 10).until(
                                    EC.presence_of_element_located((By.TAG_NAME, "body"))
                                )

                                logging.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ—à–ª–∏ –≤ –º–∞–≥–∞–∑–∏–Ω")
                                return shop_url

                        except Exception as e:
                            logging.debug(f"‚ö†Ô∏è –≠–ª–µ–º–µ–Ω—Ç –Ω–µ –∫–ª–∏–∫–∞–±–µ–ª–µ–Ω: {e}")
                            continue

                except Exception as e:
                    logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º {selector}: {e}")
                    continue

            logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏ –∫–ª–∏–∫–Ω—É—Ç—å –Ω–∞ –∫–Ω–æ–ø–∫—É '–ú–∞–≥–∞–∑–∏–Ω'")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            screenshot_path = f"/app/screenshots/no_shop_button_{int(time.time())}.png"
            self.driver.save_screenshot(screenshot_path)
            logging.info(f"üì∏ –°–æ—Ö—Ä–∞–Ω–µ–Ω —Å–∫—Ä–∏–Ω—à–æ—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏: {screenshot_path}")

            return None

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∏–∫–µ –Ω–∞ –∫–Ω–æ–ø–∫—É –º–∞–≥–∞–∑–∏–Ω–∞: {e}")
            return None

    def extract_legal_info_from_modal(self):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞ '–û –º–∞–≥–∞–∑–∏–Ω–µ'"""
        try:
            logging.info("‚öñÔ∏è –ò—â–µ–º –∏ –æ—Ç–∫—Ä—ã–≤–∞–µ–º –º–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –º–∞–≥–∞–∑–∏–Ω–µ...")

            legal_data = {}

            # üî• –°–ï–õ–ï–ö–¢–û–†–´ –î–õ–Ø –û–¢–ö–†–´–¢–ò–Ø –ú–û–î–ê–õ–¨–ù–û–ì–û –û–ö–ù–ê
            modal_button_selectors = [
                # –û—Å–Ω–æ–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–∞–≥–∞–∑–∏–Ω–µ
                "button[data-widget*='webSeller']",
                "a[href*='#info']",
                "button[class*='info']",
                "div[class*='seller-info'] button",
                "//button[contains(., '–û –º–∞–≥–∞–∑–∏–Ω–µ')]",
                "//a[contains(., '–û –º–∞–≥–∞–∑–∏–Ω–µ')]",
                "//*[contains(., '–º–∞–≥–∞–∑–∏–Ω') and contains(@class, 'button')]",
                "//*[@data-widget='webSellerName']//button",  # –ö–Ω–æ–ø–∫–∞ —Ä—è–¥–æ–º —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º –º–∞–≥–∞–∑–∏–Ω–∞
                "//*[contains(@class, 'seller')]//button[contains(@class, 'info')]"
            ]

            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∏ –∫–ª–∏–∫–Ω—É—Ç—å –Ω–∞ –∫–Ω–æ–ø–∫—É –æ—Ç–∫—Ä—ã—Ç–∏—è –º–æ–¥–∞–ª–∫–∏
            modal_opened = False
            for selector in modal_button_selectors:
                try:
                    if selector.startswith("//"):
                        elements = self.driver.find_elements(By.XPATH, selector)
                    else:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    for element in elements:
                        if element.is_displayed():
                            logging.info(f"üéØ –ù–∞—à–ª–∏ –∫–Ω–æ–ø–∫—É –æ—Ç–∫—Ä—ã—Ç–∏—è –º–æ–¥–∞–ª–∫–∏: {selector}")
                            self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", element)
                            time.sleep(1)
                            self.driver.execute_script("arguments[0].click();", element)
                            time.sleep(3)
                            modal_opened = True
                            break
                    if modal_opened:
                        break
                except:
                    continue

            if not modal_opened:
                logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –º–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ")
                return legal_data

            # ‚ö° –ò–ó–í–õ–ï–ö–ê–ï–ú –î–ê–ù–ù–´–ï –ò–ó –ú–û–î–ê–õ–¨–ù–û–ì–û –û–ö–ù–ê

            # 1. –û–ì–†–ù (–∏–∑ —Ç–µ–∫—Å—Ç–∞ –≤–Ω–∏–∑—É –º–æ–¥–∞–ª–∫–∏)
            try:
                # –ò—â–µ–º –±–ª–æ–∫ —Å —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
                legal_text_selectors = [
                    "//div[contains(@class, 'bq03_0_2-a')]//span[contains(@class, 'tsBody400Small')]",
                    "//*[contains(@class, 'tsBody400Small') and contains(text(), '10477')]",
                    "//*[contains(text(), '1047796071839')]"
                ]

                for selector in legal_text_selectors:
                    try:
                        elements = self.driver.find_elements(By.XPATH, selector)
                        for element in elements:
                            text = element.text.strip()
                            # –ò—â–µ–º 13-–∑–Ω–∞—á–Ω—ã–π –Ω–æ–º–µ—Ä (–û–ì–†–ù)
                            import re
                            ogrn_match = re.search(r'\b\d{13}\b', text)
                            if ogrn_match:
                                legal_data['–û–ì–†–ù'] = ogrn_match.group()
                                logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω –û–ì–†–ù: {legal_data['–û–ì–†–ù']}")
                                break

                            # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ —Ç–µ–∫—Å—Ç —Å –û–û–û - –∏–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏
                            if '–û–û–û' in text or '–ê–û' in text or '–ò–ü' in text:
                                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏
                                company_name = text.split('\n')[0]
                                legal_data['–ù–∞–∑–≤–∞–Ω–∏–µ_—é—Ä_–ª–∏—Ü–∞'] = company_name
                                logging.info(f"‚úÖ –ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏: {company_name}")

                    except:
                        continue
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –û–ì–†–ù: {e}")
                legal_data['–û–ì–†–ù'] = ''

            # 2. –†–ï–ô–¢–ò–ù–ì (–∏–∑ –º–æ–¥–∞–ª–∫–∏)
            try:
                rating_selectors = [
                    "//div[contains(@class, 'b5_4_4-b0') and contains(text(), '–∏–∑ 5')]",
                    "//*[contains(text(), '–∏–∑ 5')]",
                    "//*[contains(@title, '–∏–∑ 5')]"
                ]
                for selector in rating_selectors:
                    try:
                        element = self.driver.find_element(By.XPATH, selector)
                        text = element.text.strip()
                        if '–∏–∑ 5' in text:
                            legal_data['–†–µ–π—Ç–∏–Ω–≥'] = text
                            break
                    except:
                        continue
            except:
                legal_data['–†–µ–π—Ç–∏–Ω–≥'] = ''

            # 3. –û–¢–ó–´–í–´
            try:
                reviews_selectors = [
                    "//*[contains(text(), '–æ—Ç–∑—ã–≤')]/following-sibling::div//div[contains(@class, 'b5_4_4-b0')]",
                    "//div[contains(@class, 'b5_4_4-b0') and (contains(text(), 'K') or contains(text(), '—Ç—ã—Å') or contains(text(), '–æ—Ç–∑—ã–≤'))]"
                ]
                for selector in reviews_selectors:
                    try:
                        element = self.driver.find_element(By.XPATH, selector)
                        text = element.text.strip()
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —á–∏—Å–ª–æ (–º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å K, —Ç—ã—Å –∏ —Ç.–¥.)
                        if any(char.isdigit() for char in text):
                            legal_data['–û—Ç–∑—ã–≤—ã'] = text
                            break
                    except:
                        continue
            except:
                legal_data['–û—Ç–∑—ã–≤—ã'] = ''

            # 4. –ó–ê–ö–ê–ó–´
            try:
                orders_selectors = [
                    "//*[contains(text(), '–ó–∞–∫–∞–∑–æ–≤')]/following-sibling::div//div[contains(@class, 'b5_4_4-b0')]",
                    "//div[contains(@class, 'b5_4_4-b0') and (contains(text(), 'M') or contains(text(), '—Ç—ã—Å') or contains(text(), '–∑–∞–∫–∞–∑'))]"
                ]
                for selector in orders_selectors:
                    try:
                        element = self.driver.find_element(By.XPATH, selector)
                        text = element.text.strip()
                        if any(char.isdigit() for char in text):
                            legal_data['–ó–∞–∫–∞–∑—ã'] = text
                            break
                    except:
                        continue
            except:
                legal_data['–ó–∞–∫–∞–∑—ã'] = ''

            # 5. –°–†–û–ö –†–ï–ì–ò–°–¢–†–ê–¶–ò–ò
            try:
                registration_selectors = [
                    "//*[contains(text(), '–†–∞–±–æ—Ç–∞–µ—Ç —Å Ozon')]/following-sibling::div//div[contains(@class, 'b5_4_4-b0')]",
                    "//*[contains(text(), '–†–∞–±–æ—Ç–∞–µ—Ç —Å')]/following-sibling::div//div[contains(@class, 'b5_4_4-b0')]",
                    "//*[contains(text(), '–ù–∞ Ozon —Å')]",
                    "//*[contains(@title, '–ª–µ—Ç') or contains(@title, '–≥–æ–¥') or contains(@title, '–º–µ—Å—è—Ü')]",
                    "//div[contains(@class, 'b5_4_4-b0') and (contains(text(), '–ª–µ—Ç') or contains(text(), '–≥–æ–¥') or contains(text(), '–º–µ—Å—è—Ü'))]"
                ]

                for selector in registration_selectors:
                    try:
                        if selector.startswith("//"):
                            elements = self.driver.find_elements(By.XPATH, selector)
                        else:
                            elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                        for element in elements:
                            text = element.text.strip()
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –µ–¥–∏–Ω–∏—Ü—ã
                            if any(word in text.lower() for word in ['–ª–µ—Ç', '–≥–æ–¥', '–º–µ—Å—è—Ü', '–¥–µ–Ω—å']):
                                legal_data['–°—Ä–æ–∫_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏'] = text
                                logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω —Å—Ä–æ–∫ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏: {text}")
                                break
                        if legal_data.get('–°—Ä–æ–∫_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏'):
                            break
                    except:
                        continue

                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ª—é–±–æ–π —ç–ª–µ–º–µ–Ω—Ç —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
                if not legal_data.get('–°—Ä–æ–∫_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏'):
                    try:
                        all_elements = self.driver.find_elements(By.XPATH,
                                                                 "//*[contains(text(), '–†–∞–±–æ—Ç–∞–µ—Ç —Å Ozon')]//following::div[1]//div")
                        for element in all_elements:
                            text = element.text.strip()
                            if any(word in text.lower() for word in ['–ª–µ—Ç', '–≥–æ–¥', '–º–µ—Å—è—Ü']):
                                legal_data['–°—Ä–æ–∫_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏'] = text
                                break
                    except:
                        pass

            except Exception as e:
                logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Å—Ä–æ–∫ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏: {e}")
                legal_data['–°—Ä–æ–∫_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏'] = ''

            # 6. –í–ï–ë-–°–ê–ô–¢ (–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏)
            try:
                # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å —Å–∞–π—Ç–æ–º –∫–æ–º–ø–∞–Ω–∏–∏
                all_links = self.driver.find_elements(By.TAG_NAME, "a")
                for link in all_links:
                    href = link.get_attribute('href') or ''
                    text = link.text.strip()
                    if ('http' in href and 'ozon.ru' not in href and
                            not href.startswith('javascript') and len(text) > 3):
                        legal_data['–í–µ–±-—Å–∞–π—Ç'] = href
                        break
            except:
                legal_data['–í–µ–±-—Å–∞–π—Ç'] = ''

            # üî• –ó–ê–ö–†–´–í–ê–ï–ú –ú–û–î–ê–õ–¨–ù–û–ï –û–ö–ù–û
            try:
                close_selectors = [
                    "button[class*='b65_4_8-b1']",  # –ö–Ω–æ–ø–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è –∏–∑ –≤–∞—à–µ–≥–æ HTML
                    "button[aria-label*='–ó–∞–∫—Ä—ã—Ç—å']",
                    "//button[contains(@class, 'b65_4_8-b1')]",
                    "//button[contains(., '–ü–æ–Ω—è—Ç–Ω–æ')]",
                    "button.b25_4_4-a0"  # –ö–Ω–æ–ø–∫–∞ "–ü–æ–Ω—è—Ç–Ω–æ" –∏–∑ –≤–∞—à–µ–≥–æ HTML
                ]

                for selector in close_selectors:
                    try:
                        if selector.startswith("//"):
                            close_btn = self.driver.find_element(By.XPATH, selector)
                        else:
                            close_btn = self.driver.find_element(By.CSS_SELECTOR, selector)

                        if close_btn.is_displayed():
                            self.driver.execute_script("arguments[0].click();", close_btn)
                            time.sleep(2)
                            logging.info("‚úÖ –ú–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ –∑–∞–∫—Ä—ã—Ç–æ")
                            break
                    except:
                        continue
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–∫—Ä—ã—Ç—å –º–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ: {e}")

            logging.info(f"‚úÖ –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∞: {legal_data}")
            return legal_data

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {e}")
            return {}

    def extract_shop_info(self):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –º–∞–≥–∞–∑–∏–Ω–∞"""
        try:
            data = {}

            # –û–∂–∏–¥–∞–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            time.sleep(random.uniform(3, 5))

            # –ù–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞
            try:
                name_selectors = [
                    "h1",
                    ".seller-name",
                    "[data-widget='webSellerName']",
                    ".shop-title",
                    "//h1[contains(@class, 'title')]"
                ]
                for selector in name_selectors:
                    try:
                        if selector.startswith("//"):
                            element = self.driver.find_element(By.XPATH, selector)
                        else:
                            element = self.driver.find_element(By.CSS_SELECTOR, selector)
                        if element.text.strip():
                            data['–ù–∞–∑–≤–∞–Ω–∏–µ'] = element.text.strip()
                            break
                    except:
                        continue
            except:
                data['–ù–∞–∑–≤–∞–Ω–∏–µ'] = ''

            # –†–µ–π—Ç–∏–Ω–≥
            try:
                rating_selectors = [
                    "[data-widget*='rating']",
                    ".seller-rating",
                    ".rating-value",
                    "//*[contains(@class, 'rating')]"
                ]
                for selector in rating_selectors:
                    try:
                        if selector.startswith("//"):
                            element = self.driver.find_element(By.XPATH, selector)
                        else:
                            element = self.driver.find_element(By.CSS_SELECTOR, selector)
                        if element.text.strip():
                            data['–†–µ–π—Ç–∏–Ω–≥'] = element.text.strip()
                            break
                    except:
                        continue
            except:
                data['–†–µ–π—Ç–∏–Ω–≥'] = ''

            # –û—Ç–∑—ã–≤—ã
            try:
                reviews_selectors = [
                    "[data-widget*='reviews']",
                    ".reviews-count",
                    "//*[contains(., '–æ—Ç–∑—ã–≤')]"
                ]
                for selector in reviews_selectors:
                    try:
                        if selector.startswith("//"):
                            element = self.driver.find_element(By.XPATH, selector)
                        else:
                            element = self.driver.find_element(By.CSS_SELECTOR, selector)
                        if element.text.strip():
                            data['–û—Ç–∑—ã–≤—ã'] = element.text.strip()
                            break
                    except:
                        continue
            except:
                data['–û—Ç–∑—ã–≤—ã'] = ''

            # –ó–∞–∫–∞–∑—ã
            try:
                orders_selectors = [
                    "[data-widget*='orders']",
                    "//*[contains(., '–∑–∞–∫–∞–∑')]"
                ]
                for selector in orders_selectors:
                    try:
                        if selector.startswith("//"):
                            element = self.driver.find_element(By.XPATH, selector)
                        else:
                            element = self.driver.find_element(By.CSS_SELECTOR, selector)
                        if element.text.strip():
                            data['–ó–∞–∫–∞–∑—ã'] = element.text.strip()
                            break
                    except:
                        continue
            except:
                data['–ó–∞–∫–∞–∑—ã'] = ''

            # –û–ø–∏—Å–∞–Ω–∏–µ
            try:
                desc_selectors = [
                    ".seller-description",
                    "[data-widget*='description']",
                    "//*[contains(@class, 'description')]"
                ]
                for selector in desc_selectors:
                    try:
                        if selector.startswith("//"):
                            element = self.driver.find_element(By.XPATH, selector)
                        else:
                            element = self.driver.find_element(By.CSS_SELECTOR, selector)
                        if element.text.strip():
                            data['–û–ø–∏—Å–∞–Ω–∏–µ'] = element.text.strip()[:500]
                            break
                    except:
                        continue
            except:
                data['–û–ø–∏—Å–∞–Ω–∏–µ'] = ''

            # –°—Ä–æ–∫ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏
            try:
                registration_selectors = [
                    "//*[contains(., '–ù–∞ Ozon —Å')]",
                    "//*[contains(., '—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è')]",
                    "//*[contains(., '—Å ') and contains(., '20')]"
                ]
                for selector in registration_selectors:
                    try:
                        element = self.driver.find_element(By.XPATH, selector)
                        if element.text.strip():
                            data['–°—Ä–æ–∫_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏'] = element.text.strip()
                            break
                    except:
                        continue
            except:
                data['–°—Ä–æ–∫_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏'] = ''

            # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤
            try:
                total_products_selectors = [
                    "//*[contains(., '—Ç–æ–≤–∞—Ä') and contains(., '—à—Ç')]",
                    "//*[contains(., '–¢–æ–≤–∞—Ä—ã')]",
                    "[data-widget*='totalProducts']"
                ]
                for selector in total_products_selectors:
                    try:
                        if selector.startswith("//"):
                            element = self.driver.find_element(By.XPATH, selector)
                        else:
                            element = self.driver.find_element(By.CSS_SELECTOR, selector)
                        if element.text.strip():
                            data['–û–±—â–µ–µ_–∫–æ–ª-–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤'] = element.text.strip()
                            break
                    except:
                        continue
            except:
                data['–û–±—â–µ–µ_–∫–æ–ª-–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤'] = ''

            return data

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–∞–≥–∞–∑–∏–Ω–µ: {e}")
            return {}

    def parse_seller(self, seller_id):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø—Ä–æ–¥–∞–≤—Ü–∞ —Å —Ä–æ—Ç–∞—Ü–∏–µ–π –ø—Ä–æ–∫—Å–∏"""
        url = f"https://www.ozon.ru/seller/{seller_id}"

        # üîÑ –ü–†–û–í–ï–†–ö–ê –†–û–¢–ê–¶–ò–ò –ü–ï–†–ï–î –ù–ê–ß–ê–õ–û–ú –ü–ê–†–°–ò–ù–ì–ê
        if self.proxy_list:
            self.requests_per_proxy += 1
            proxy_rotation_count = int(os.getenv('PROXY_ROTATION_COUNT', 5))

            if self.requests_per_proxy >= proxy_rotation_count:
                logging.info(f"üîÑ –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤ ({self.requests_per_proxy}) –¥–ª—è –ø—Ä–æ–∫—Å–∏, —Ä–æ—Ç–∏—Ä—É–µ–º...")
                self.rotate_proxy()

        # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–∫—Å–∏
        proxy_info = f" [–ü—Ä–æ–∫—Å–∏: {self.current_proxy}]" if self.current_proxy else " [–ë–µ–∑ –ø—Ä–æ–∫—Å–∏]"
        proxy_count_info = f" [–ó–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ –ø—Ä–æ–∫—Å–∏: {self.requests_per_proxy}]" if self.proxy_list else ""
        logging.info(f"üîç –ü–∞—Ä—Å–∏–º –ø—Ä–æ–¥–∞–≤—Ü–∞ {seller_id}{proxy_info}{proxy_count_info}")

        seller_data = {'URL': url}

        try:
            # === –≠–¢–ê–ü 1: –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø—Ä–æ–¥–∞–≤—Ü–∞ ===
            logging.info(f"üåê –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø—Ä–æ–¥–∞–≤—Ü–∞: {url}")
            self.driver.get(url)
            time.sleep(random.uniform(5, 8))

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫—É
            page_source = self.driver.page_source.lower()
            blocking_indicators = [
                "—Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", "404", "–¥–æ—Å—Ç—É–ø –æ–≥—Ä–∞–Ω–∏—á–µ–Ω",
                "captcha", "bot", "automation", "–¥–æ—Å—Ç—É–ø –∑–∞–ø—Ä–µ—â–µ–Ω",
                "blocked", "cloudflare", "–Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
            ]

            if any(phrase in page_source for phrase in blocking_indicators):
                screenshot_path = f"/app/screenshots/error_{seller_id}_{int(time.time())}.png"
                self.driver.save_screenshot(screenshot_path)
                time.sleep(2)

                # üîÑ –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–ê–Ø –†–û–¢–ê–¶–ò–Ø –ü–†–ò –ë–õ–û–ö–ò–†–û–í–ö–ï
                if ("–¥–æ—Å—Ç—É–ø –æ–≥—Ä–∞–Ω–∏—á–µ–Ω" in page_source or "blocked" in page_source) and self.proxy_list:
                    logging.warning(f"üö´ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞, –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Ä–æ—Ç–∏—Ä—É–µ–º –ø—Ä–æ–∫—Å–∏...")
                    self.rotate_proxy()

                if "–¥–æ—Å—Ç—É–ø –æ–≥—Ä–∞–Ω–∏—á–µ–Ω" in page_source or "blocked" in page_source:
                    logging.warning(f"üö´ –ü—Ä–æ–¥–∞–≤–µ—Ü {seller_id} –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω{proxy_info}. –°–∫—Ä–∏–Ω—à–æ—Ç: {screenshot_path}")
                elif "—Å—Ç—Ä–∞–Ω–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞" in page_source or "404" in page_source:
                    logging.warning(f"‚ùì –ü—Ä–æ–¥–∞–≤–µ—Ü {seller_id} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç{proxy_info}")
                else:
                    logging.warning(
                        f"‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è –ø—Ä–æ–¥–∞–≤—Ü–∞ {seller_id}{proxy_info}. –°–∫—Ä–∏–Ω—à–æ—Ç: {screenshot_path}")
                return None

            # === –≠–¢–ê–ü 2: –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã ===
            seller_data['Html_–ø—É—Ç—å'] = self.save_html_page(seller_id, "main_")

            # === –≠–¢–ê–ü 3: –ü–∞—Ä—Å–∏–º —Ç–æ–≤–∞—Ä—ã —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã ===
            logging.info("üõí –ü–∞—Ä—Å–∏–º —Ç–æ–≤–∞—Ä—ã —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")
            products = self.extract_products_from_main_page()
            seller_data['–ö–æ–ª-–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤_–Ω–∞_—Å—Ç—Ä–∞–Ω–∏—Ü–µ'] = len(products)
            seller_data['–¢–æ–≤–∞—Ä—ã_JSON'] = json.dumps(products, ensure_ascii=False)
            logging.info(f"‚úÖ –°–ø–∞—Ä—Å–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(products)}")

            # === –≠–¢–ê–ü 4: –°–∫—Ä–æ–ª–ª–∏–º –∫ –≤–µ—Ä—Ö—É –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–Ω–æ–ø–∫–∏ "–ú–∞–≥–∞–∑–∏–Ω" ===
            logging.info("‚¨ÜÔ∏è –°–∫—Ä–æ–ª–ª–∏–º –∫ –≤–µ—Ä—Ö—É –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–Ω–æ–ø–∫–∏ '–ú–∞–≥–∞–∑–∏–Ω'...")
            self.driver.execute_script("window.scrollTo(0, 0);")
            time.sleep(3)

            # === –≠–¢–ê–ü 5: –ò—â–µ–º –∏ –∫–ª–∏–∫–∞–µ–º –∫–Ω–æ–ø–∫—É "–ú–∞–≥–∞–∑–∏–Ω" ===
            logging.info("üõçÔ∏è –ò—â–µ–º –∫–Ω–æ–ø–∫—É '–ú–∞–≥–∞–∑–∏–Ω'...")
            shop_url = self.click_shop_button()

            if not shop_url:
                logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∫–Ω–æ–ø–∫—É '–ú–∞–≥–∞–∑–∏–Ω' –¥–ª—è –ø—Ä–æ–¥–∞–≤—Ü–∞ {seller_id}")
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ, —á—Ç–æ —É—Å–ø–µ–ª–∏ —Å–æ–±—Ä–∞—Ç—å
                if products:
                    self.save_to_csv(seller_data)
                    logging.info(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –±–µ–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–∞–≥–∞–∑–∏–Ω–µ")
                return seller_data

            seller_data['–°—Å—ã–ª–∫–∞_–Ω–∞_–º–∞–≥–∞–∑–∏–Ω'] = shop_url
            logging.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ—à–ª–∏ –≤ –º–∞–≥–∞–∑–∏–Ω: {shop_url}")

            # === –≠–¢–ê–ü 6: –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã –º–∞–≥–∞–∑–∏–Ω–∞ ===
            seller_data['Html_–ø—É—Ç—å'] += f"; {self.save_html_page(seller_id, 'shop_')}"

            # === –≠–¢–ê–ü 7: –ü–∞—Ä—Å–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–∞–≥–∞–∑–∏–Ω–µ ===
            logging.info("üè™ –ü–∞—Ä—Å–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–∞–≥–∞–∑–∏–Ω–µ...")
            shop_info = self.extract_shop_info()
            seller_data.update(shop_info)

            # === –≠–¢–ê–ü 8: –ü–∞—Ä—Å–∏–º —é—Ä–∏–¥–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é ===
            logging.info("‚öñÔ∏è –ü–∞—Ä—Å–∏–º —é—Ä–∏–¥–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é...")
            legal_info = self.extract_legal_info_from_modal()
            seller_data.update(legal_info)

            # === –≠–¢–ê–ü 9: –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ ===
            if self.save_to_csv(seller_data):
                logging.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –ø—Ä–æ–¥–∞–≤–µ—Ü {seller_id}{proxy_info}")
                return seller_data
            else:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ–¥–∞–≤—Ü–∞ {seller_id}{proxy_info}")
                return None

        except Exception as e:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–µ
            screenshot_path = f"/app/screenshots/crash_{seller_id}_{int(time.time())}.png"
            try:
                self.driver.save_screenshot(screenshot_path)
                time.sleep(2)
                logging.error(f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {seller_id}{proxy_info}. –°–∫—Ä–∏–Ω—à–æ—Ç: {screenshot_path}",
                              exc_info=True)
            except:
                logging.error(f"üí• –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {seller_id}: {e}", exc_info=True)
            return None

    def close(self):
        """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ –¥—Ä–∞–π–≤–µ—Ä–∞ –∏ –æ—á–∏—Å—Ç–∫–∞"""
        if self.driver:
            try:
                self.driver.quit()
            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –¥—Ä–∞–π–≤–µ—Ä–∞: {e}")
            self.driver = None

        if self.chrome_temp_dir and os.path.exists(self.chrome_temp_dir):
            try:
                shutil.rmtree(self.chrome_temp_dir)
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é: {e}")


def callback(ch, method, properties, body):
    seller_id = body.decode()
    logging.info(f"üéØ –ü–æ–ª—É—á–µ–Ω ID –ø—Ä–æ–¥–∞–≤—Ü–∞: {seller_id}")

    parser = None
    try:
        parser = OzonSellerParser()
        result = parser.parse_seller(seller_id)
        if result:
            logging.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –ø—Ä–æ–¥–∞–≤–µ—Ü {seller_id}")
        else:
            logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø—Ä–æ–¥–∞–≤—Ü–∞ {seller_id}")
        time.sleep(random.uniform(4, 5))
    except Exception as e:
        logging.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {seller_id}: {e}", exc_info=True)
    finally:
        if parser:
            parser.close()
    ch.basic_ack(delivery_tag=method.delivery_tag)


def start_consumer():
    while True:
        try:
            connection = pika.BlockingConnection(
                pika.ConnectionParameters(
                    host=os.getenv('RABBITMQ_HOST', 'rabbitmq'),
                    credentials=pika.PlainCredentials(
                        os.getenv('RABBITMQ_USER', 'admin'),
                        os.getenv('RABBITMQ_PASS', 'guest')
                    ),
                    heartbeat=600
                )
            )
            channel = connection.channel()
            channel.queue_declare(queue='seller_ids', durable=True)
            channel.basic_qos(prefetch_count=1)
            channel.basic_consume(queue='seller_ids', on_message_callback=callback)
            logging.info("üîÑ –û–∂–∏–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ RabbitMQ...")
            channel.start_consuming()
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ RabbitMQ: {e}", exc_info=True)
            time.sleep(10)


if __name__ == "__main__":
    start_consumer()