import csv
import logging
import random
import time
import os
import sys
import tempfile
import shutil
import json
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium_stealth import stealth
from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.core.os_manager import ChromeType
import pika
from concurrent.futures import ThreadPoolExecutor
import threading

# –ü–ï–†–ï–ú–ï–°–¢–ò–¢–ï –í–°–ï –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Æ –ü–û–°–õ–ï –ò–ú–ü–û–†–¢–û–í
executor = ThreadPoolExecutor(max_workers=5)
lock = threading.Lock()

# –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫–∏ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
os.makedirs("/app/logs", exist_ok=True)
os.makedirs("/app/data", exist_ok=True)
os.makedirs("/app/screenshots", exist_ok=True)
os.makedirs("/app/html", exist_ok=True)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –î–û –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/app/logs/parser.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)

def parse_task(seller_id: str):
    parser = None
    try:
        parser = OzonSellerParser()
        result = parser.parse_seller(seller_id)
        if result:
            logging.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –ø—Ä–æ–¥–∞–≤–µ—Ü {seller_id}")
        else:
            logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø—Ä–æ–¥–∞–≤—Ü–∞ {seller_id}")
        time.sleep(random.uniform(10, 20))
    except Exception as e:
        logging.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {seller_id}: {e}", exc_info=True)
    finally:
        if parser:
            parser.close()


class OzonSellerParser:
    def __init__(self):
        self.instance_id = os.getenv('HOSTNAME', f"parser-{random.randint(1000, 9999)}")
        self.request_count = 0
        self.driver = None
        self.wait = None
        self.current_proxy = None
        self.proxy_list = []
        self.proxy_rotation_count = 0 #int(os.getenv('PROXY_ROTATION_COUNT', 3))
        self.proxy_timeout = int(os.getenv('PROXY_ROTATION_TIMEOUT', 30))
        self.screenshot_counter = 0  # –°—á–µ—Ç—á–∏–∫ —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏
        proxy_list_str = os.getenv('PROXY_LIST', '')
        if proxy_list_str:
            self.proxy_list = [p.strip() for p in proxy_list_str.split(',') if p.strip()]

        # –£–Ω–∏–∫–∞–ª—å–Ω–∞—è –≤—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è Chrome
        self.chrome_temp_dir = tempfile.mkdtemp()
        logging.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞ {self.instance_id}, –ø—Ä–æ—Ñ–∏–ª—å: {self.chrome_temp_dir}")

        try:
            self.setup_driver()
            self.wait = WebDriverWait(self.driver, 15)

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CSV
            self.data_dir = "/app/data"
            os.makedirs(self.data_dir, exist_ok=True)
            self.csv_file = f"{self.data_dir}/sellers_{self.instance_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            self.init_csv()
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä—Å–µ—Ä–∞: {e}", exc_info=True)
            self.close()
            raise

    def take_screenshot(self, prefix=""):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –Ω—É–º–µ—Ä–∞—Ü–∏–µ–π"""
        try:
            self.screenshot_counter += 1
            screenshot_path = f"/app/screenshots/{self.instance_id}_{self.screenshot_counter:03d}_{prefix}_{int(time.time())}.png"
            self.driver.save_screenshot(screenshot_path)
            logging.info(f"üì∏ –°–æ—Ö—Ä–∞–Ω–µ–Ω —Å–∫—Ä–∏–Ω—à–æ—Ç: {screenshot_path}")
            return screenshot_path
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç: {e}")
            return ""

    def create_proxy_auth_extension(self, proxy_host, proxy_port, proxy_username, proxy_password):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –¥–ª—è –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–æ–∫—Å–∏"""
        try:
            manifest_json = """
            {
                "version": "1.0.0",
                "manifest_version": 2,
                "name": "Chrome Proxy",
                "permissions": [
                    "proxy",
                    "tabs",
                    "unlimitedStorage",
                    "storage",
                    "<all_urls>",
                    "webRequest",
                    "webRequestBlocking"
                ],
                "background": {
                    "scripts": ["background.js"]
                },
                "minimum_chrome_version":"22.0.0"
            }
            """

            background_js = """
            var config = {
                mode: "fixed_servers",
                rules: {
                    singleProxy: {
                        scheme: "http",
                        host: "%s",
                        port: parseInt(%s)
                    },
                    bypassList: ["localhost"]
                }
            };

            chrome.proxy.settings.set({value: config, scope: "regular"}, function() {});

            function callbackFn(details) {
                return {
                    authCredentials: {
                        username: "%s",
                        password: "%s"
                    }
                };
            }

            chrome.webRequest.onAuthRequired.addListener(
                callbackFn,
                {urls: ["<all_urls>"]},
                ['blocking']
            );
            """ % (proxy_host, proxy_port, proxy_username, proxy_password)

            import tempfile
            import zipfile
            import os

            proxy_dir = tempfile.mkdtemp()

            with open(os.path.join(proxy_dir, "manifest.json"), "w") as f:
                f.write(manifest_json)

            with open(os.path.join(proxy_dir, "background.js"), "w") as f:
                f.write(background_js)

            proxy_ext = os.path.join(proxy_dir, "proxy_auth.zip")

            with zipfile.ZipFile(proxy_ext, 'w') as zp:
                zp.write(os.path.join(proxy_dir, "manifest.json"), "manifest.json")
                zp.write(os.path.join(proxy_dir, "background.js"), "background.js")

            logging.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–∫—Å–∏: {proxy_host}:{proxy_port}")
            return proxy_ext

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –ø—Ä–æ–∫—Å–∏: {e}")
            return None

    def rotate_proxy(self):
        """–†–æ—Ç–∞—Ü–∏—è –ø—Ä–æ–∫—Å–∏ –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –¥—Ä–∞–π–≤–µ—Ä–∞"""
        if not self.proxy_list or len(self.proxy_list) <= 1:
            logging.info("üîÑ –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏ –¥–ª—è —Ä–æ—Ç–∞—Ü–∏–∏")
            return False

        try:
            # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π –ø—Ä–æ–∫—Å–∏
            try:
                import glob
                temp_dirs = glob.glob("/tmp/tmp*")
                for temp_dir in temp_dirs:
                    try:
                        if os.path.exists(temp_dir) and "proxy_auth" in temp_dir:
                            shutil.rmtree(temp_dir, ignore_errors=True)
                            logging.debug(f"üßπ –û—á–∏—â–µ–Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {temp_dir}")
                    except Exception as e:
                        logging.debug(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å {temp_dir}: {e}")
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {e}")

            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –ø—Ä–æ–∫—Å–∏ –ø–æ –∫—Ä—É–≥—É
            if not hasattr(self, 'current_proxy_index'):
                self.current_proxy_index = 0

            old_proxy_index = self.current_proxy_index
            self.current_proxy_index = (self.current_proxy_index + 1) % len(self.proxy_list)
            new_proxy = self.proxy_list[self.current_proxy_index]

            old_proxy = self.current_proxy
            self.current_proxy = new_proxy
            self.requests_per_proxy = 0  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫

            logging.info(
                f"üîÑ –†–æ—Ç–∏—Ä—É–µ–º –ø—Ä–æ–∫—Å–∏ [{old_proxy_index + 1}‚Üí{self.current_proxy_index + 1}/{len(self.proxy_list)}]: {old_proxy} -> {new_proxy}")

            # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º –¥—Ä–∞–π–≤–µ—Ä —Å –Ω–æ–≤—ã–º –ø—Ä–æ–∫—Å–∏
            if self.driver:
                try:
                    self.driver.quit()
                    time.sleep(3)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∑–∞–∫—Ä—ã—Ç–∏—è
                except Exception as e:
                    logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –¥—Ä–∞–π–≤–µ—Ä–∞: {e}")

            # –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥—Ä–∞–π–≤–µ—Ä —Å –Ω–æ–≤—ã–º –ø—Ä–æ–∫—Å–∏
            try:
                self.setup_driver()
                self.wait = WebDriverWait(self.driver, 15)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–∫—Å–∏
                test_url = "https://httpbin.org/ip"
                self.driver.get(test_url)
                time.sleep(2)

                logging.info("‚úÖ –ü—Ä–æ–∫—Å–∏ —É—Å–ø–µ—à–Ω–æ —Å–º–µ–Ω–µ–Ω –∏ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω")
                return True

            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –¥—Ä–∞–π–≤–µ—Ä–∞ —Å –Ω–æ–≤—ã–º –ø—Ä–æ–∫—Å–∏: {e}")
                # –ü—Ä–æ–±—É–µ–º –≤–µ—Ä–Ω—É—Ç—å—Å—è –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É –ø—Ä–æ–∫—Å–∏
                try:
                    self.current_proxy_index = old_proxy_index
                    self.current_proxy = old_proxy
                    if self.driver:
                        self.driver.quit()
                    self.setup_driver()
                    self.wait = WebDriverWait(self.driver, 15)
                    logging.info("üîÑ –í–æ–∑–≤—Ä–∞—Ç –∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–º—É –ø—Ä–æ–∫—Å–∏")
                except:
                    logging.error("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ - –Ω–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –¥—Ä–∞–π–≤–µ—Ä")
                return False

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–æ—Ç–∞—Ü–∏–∏ –ø—Ä–æ–∫—Å–∏: {e}")
            # –ü—Ä–æ–±—É–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–∞–±–æ—Ç—É —Å —Ç–µ–∫—É—â–∏–º –ø—Ä–æ–∫—Å–∏
            try:
                if self.driver:
                    self.driver.quit()
                self.setup_driver()
                self.wait = WebDriverWait(self.driver, 15)
                logging.info("üîÑ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –¥—Ä–∞–π–≤–µ—Ä–∞ –ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏ —Ä–æ—Ç–∞—Ü–∏–∏")
            except Exception as restore_error:
                logging.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –¥—Ä–∞–π–≤–µ—Ä: {restore_error}")
            return False

    def setup_driver(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ Chrome –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ Docker"""
        from webdriver_manager.chrome import ChromeDriverManager
        from webdriver_manager.core.os_manager import ChromeType

        chrome_options = Options()

        # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø—Ü–∏–∏ –¥–ª—è Docker
        chrome_options.add_argument("--headless=new")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--disable-extensions")
        chrome_options.add_argument("--disable-setuid-sandbox")
        chrome_options.add_argument("--window-size=1920,1080")

        # –£–ª—É—á—à–µ–Ω–Ω—ã–µ stealth –æ–ø—Ü–∏–∏
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_argument("--disable-features=UserAgentClientHint")
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)

        # User-Agent
        user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
        ]
        chrome_options.add_argument(f"--user-agent={random.choice(user_agents)}")

        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å
        chrome_options.add_argument(f"--user-data-dir={self.chrome_temp_dir}")

        try:
            # –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ê–Ø –£–°–¢–ê–ù–û–í–ö–ê ChromeDriver
            service = Service(ChromeDriverManager(chrome_type=ChromeType.GOOGLE).install())
            self.driver = webdriver.Chrome(service=service, options=chrome_options)

            # –ü—Ä–∏–º–µ–Ω—è–µ–º stealth
            stealth(
                self.driver,
                languages=["ru-RU", "ru", "en-US", "en"],
                vendor="Google Inc.",
                platform="Win32",
                webgl_vendor="Intel Inc.",
                renderer="Intel Iris OpenGL Engine",
                fix_hairline=True,
                run_on_insecure_origins=False
            )
            logging.info("‚úÖ –î—Ä–∞–π–≤–µ—Ä —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞: {e}", exc_info=True)
            raise

    def init_csv(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CSV —Ñ–∞–π–ª–∞"""
        headers = [
            'URL', '–Ω–∞–∑–≤–∞–Ω–∏–µ', 'Html', '–û–ì–†–ù', '–ò–ù–ù', '–ù–∞–∑–≤–∞–Ω–∏–µ —é—Ä –ª–∏—Ü–∞',
            '–ö–æ–ª-–≤–æ –æ—Ç–∑—ã–≤–æ–≤', '—Ä–µ–π—Ç–∏–Ω–≥', '–°—Ä–æ–∫ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏', '–¢–æ–≤–∞—Ä—ã'
        ]
        try:
            with open(self.csv_file, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                writer.writerow(headers)
            logging.info(f"‚úÖ –°–æ–∑–¥–∞–Ω CSV —Ñ–∞–π–ª: {self.csv_file}")
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è CSV: {e}", exc_info=True)

    def save_to_csv(self, data):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ CSV"""
        try:
            with open(self.csv_file, 'a', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                writer.writerow([
                    data.get('URL', ''),
                    data.get('–ù–∞–∑–≤–∞–Ω–∏–µ', ''),
                    data.get('Html_–ø—É—Ç—å', ''),
                    data.get('–û–ì–†–ù', ''),
                    data.get('–ò–ù–ù', ''),
                    data.get('–ù–∞–∑–≤–∞–Ω–∏–µ_—é—Ä_–ª–∏—Ü–∞', ''),
                    data.get('–û—Ç–∑—ã–≤—ã', ''),
                    data.get('–†–µ–π—Ç–∏–Ω–≥', ''),
                    data.get('–°—Ä–æ–∫_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏', ''),
                    data.get('–¢–æ–≤–∞—Ä—ã_JSON', '')
                ])
                f.flush()
                os.fsync(f.fileno())
            logging.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ CSV")
            return True
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ CSV: {e}", exc_info=True)
            return False

    def save_html_page(self, seller_id, prefix=""):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            html_path = f"/app/html/{prefix}{seller_id}_{int(time.time())}.html"
            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(self.driver.page_source)
            return html_path
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å HTML: {e}")
            return ""

    def extract_products_from_main_page(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ç–æ–≤–∞—Ä–æ–≤ —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            logging.info("üõí –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Ç–æ–≤–∞—Ä–æ–≤ —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")

            # –ñ–¥–µ–º –ø–æ—è–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ —Å —Ç–æ–≤–∞—Ä–∞–º–∏
            try:
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located(
                        (By.CSS_SELECTOR, "div[data-widget*='paginator'], div[data-widget*='tileGrid'], div.tile-root"))
                )
            except:
                logging.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å —Ç–æ–≤–∞—Ä–∞–º–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫")
                return []

            products = []

            # ‚ö° –û–°–ù–û–í–ù–´–ï –°–ï–õ–ï–ö–¢–û–†–´ –î–õ–Ø –ö–ê–†–¢–û–ß–ï–ö –¢–û–í–ê–†–û–í ‚ö°
            # –ò—â–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ —Ä–∞–∑–Ω—ã–º —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º
            product_selectors = [
                "div.tile-root[data-index]",  # –û—Å–Ω–æ–≤–Ω–æ–π —Å–µ–ª–µ–∫—Ç–æ—Ä
                "div[data-widget*='tileGrid'] div.tile-root",  # –í–Ω—É—Ç—Ä–∏ tileGrid
                "#paginator div.tile-root",  # –í–Ω—É—Ç—Ä–∏ –ø–∞–≥–∏–Ω–∞—Ç–æ—Ä–∞
                "div[data-index]"  # –õ—é–±–æ–π —ç–ª–µ–º–µ–Ω—Ç —Å data-index
            ]

            product_cards = []
            for selector in product_selectors:
                try:
                    cards = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if cards:
                        product_cards = cards
                        logging.info(f"üì¶ –ù–∞–π–¥–µ–Ω–æ –∫–∞—Ä—Ç–æ—á–µ–∫ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ —Å–µ–ª–µ–∫—Ç–æ—Ä—É '{selector}': {len(cards)}")
                        break
                except:
                    continue

            if not product_cards:
                logging.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∫–∞—Ä—Ç–æ—á–µ–∫ —Ç–æ–≤–∞—Ä–æ–≤")
                return []

            # –ü–∞—Ä—Å–∏–º —Ç–æ–ª—å–∫–æ –≤–∏–¥–∏–º—ã–µ –∫–∞—Ä—Ç–æ—á–∫–∏ (–ø–µ—Ä–≤—ã–µ 20 –∏–ª–∏ –≤—Å–µ –≤–∏–¥–∏–º—ã–µ)
            visible_cards = [card for card in product_cards if card.is_displayed()][:20]
            logging.info(f"üéØ –ü–∞—Ä—Å–∏–º –≤–∏–¥–∏–º—ã—Ö –∫–∞—Ä—Ç–æ—á–µ–∫: {len(visible_cards)}")

            for card in visible_cards:
                try:
                    product_data = {}

                    # 1. –ù–ê–ó–í–ê–ù–ò–ï –¢–û–í–ê–†–ê
                    try:
                        # –ò—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –º–µ—Å—Ç–µ
                        name_selectors = [
                            ".bq03_0_2-a span.tsBody500Medium",  # –û—Å–Ω–æ–≤–Ω–æ–π —Å–µ–ª–µ–∫—Ç–æ—Ä –Ω–∞–∑–≤–∞–Ω–∏—è
                            "a[href*='/product/'] .bq03_0_2-a span",  # –í —Å—Å—ã–ª–∫–µ
                            ".tsBody500Medium",  # –ü–æ –∫–ª–∞—Å—Å—É —Ç–µ–∫—Å—Ç–∞
                            "span[class*='tsBody500']"  # –õ—é–±–æ–π span —Å —Ç–µ–∫—Å—Ç–æ–º
                        ]

                        for name_selector in name_selectors:
                            try:
                                name_elem = card.find_element(By.CSS_SELECTOR, name_selector)
                                name_text = name_elem.text.strip()
                                if name_text and len(name_text) > 5:  # –ù–∞–∑–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–º
                                    product_data['name'] = name_text
                                    break
                            except:
                                continue

                        if not product_data.get('name'):
                            product_data['name'] = ''

                    except Exception as e:
                        logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏—è: {e}")
                        product_data['name'] = ''

                    # 2. –¶–ï–ù–ê –¢–û–í–ê–†–ê
                    try:
                        # –û—Å–Ω–æ–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã —Ü–µ–Ω—ã
                        price_selectors = [
                            ".c35_3_8-a1.tsHeadline500Medium",  # –û—Å–Ω–æ–≤–Ω–∞—è —Ü–µ–Ω–∞
                            "span[class*='tsHeadline500Medium']",  # –¶–µ–Ω–∞ –ø–æ –∫–ª–∞—Å—Å—É
                            ".c35_3_8-a0 span",  # –í –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ —Ü–µ–Ω—ã
                            "//span[contains(text(), '‚ÇΩ')]"  # –õ—é–±–æ–π —ç–ª–µ–º–µ–Ω—Ç —Å —Å–∏–º–≤–æ–ª–æ–º —Ä—É–±–ª—è
                        ]

                        for price_selector in price_selectors:
                            try:
                                if price_selector.startswith("//"):
                                    price_elems = card.find_elements(By.XPATH, price_selector)
                                else:
                                    price_elems = card.find_elements(By.CSS_SELECTOR, price_selector)

                                for elem in price_elems:
                                    text = elem.text.strip()
                                    # –ò—â–µ–º —Ü–µ–Ω—É —Å —Å–∏–º–≤–æ–ª–æ–º —Ä—É–±–ª—è –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Ü–∏—Ñ—Ä—ã
                                    if '‚ÇΩ' in text or (any(char.isdigit() for char in text) and len(text) <= 20):
                                        product_data['price'] = text
                                        break
                                if product_data.get('price'):
                                    break
                            except:
                                continue

                        if not product_data.get('price'):
                            product_data['price'] = ''

                    except Exception as e:
                        logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Ü–µ–Ω—ã: {e}")
                        product_data['price'] = ''

                    # 3. –°–°–´–õ–ö–ê –ù–ê –¢–û–í–ê–†
                    try:
                        link_selectors = [
                            "a[href*='/product/']",  # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ —Ç–æ–≤–∞—Ä
                            ".tile-clickable-element[href*='/product/']"  # –ö–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç
                        ]

                        for link_selector in link_selectors:
                            try:
                                link_elem = card.find_element(By.CSS_SELECTOR, link_selector)
                                href = link_elem.get_attribute('href')
                                if href and '/product/' in href:
                                    product_data['link'] = href if href.startswith(
                                        'http') else f"https://www.ozon.ru{href}"
                                    break
                            except:
                                continue

                        if not product_data.get('link'):
                            product_data['link'] = ''

                    except Exception as e:
                        logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Å—Å—ã–ª–∫–∏: {e}")
                        product_data['link'] = ''

                    # 4. –§–û–¢–û –¢–û–í–ê–†–ê
                    try:
                        img_selectors = [
                            "img.i4s_24.b95_3_3-a",
                            "img[loading='eager']",
                            "img[src*='ozon.ru']",
                            "img.b95_3_3-a"
                        ]

                        for img_selector in img_selectors:
                            try:
                                img_elem = card.find_element(By.CSS_SELECTOR, img_selector)
                                img_src = img_elem.get_attribute('src')
                                if img_src and 'ozon.ru' in img_src:
                                    product_data['image'] = img_src
                                    break
                            except:
                                continue

                        if not product_data.get('image'):
                            product_data['image'] = ''

                    except Exception as e:
                        logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Ñ–æ—Ç–æ: {e}")
                        product_data['image'] = ''

                    # 5. –†–ï–ô–¢–ò–ù–ì –¢–û–í–ê–†–ê
                    try:
                        rating_selectors = [
                            ".p6b3_0_2-a4 span[style*='color:var(--textPremium)']",  # –†–µ–π—Ç–∏–Ω–≥
                            "span[style*='color:var(--textPremium)']",  # –ü–æ —Ü–≤–µ—Ç—É
                            "//span[contains(@style, 'textPremium')]"  # XPath –ø–æ —Å—Ç–∏–ª—é
                        ]

                        for rating_selector in rating_selectors:
                            try:
                                if rating_selector.startswith("//"):
                                    rating_elems = card.find_elements(By.XPATH, rating_selector)
                                else:
                                    rating_elems = card.find_elements(By.CSS_SELECTOR, rating_selector)

                                for elem in rating_elems:
                                    text = elem.text.strip()
                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Ä–µ–π—Ç–∏–Ω–≥ (—á–∏—Å–ª–æ —Å —Ç–æ—á–∫–æ–π –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ)
                                    if text and ('.' in text or text.replace('.', '').isdigit()):
                                        product_data['rating'] = text
                                        break
                                if product_data.get('rating'):
                                    break
                            except:
                                continue

                        if not product_data.get('rating'):
                            product_data['rating'] = ''

                    except Exception as e:
                        logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Ä–µ–π—Ç–∏–Ω–≥–∞: {e}")
                        product_data['rating'] = ''

                    # 6. –ö–û–õ–ò–ß–ï–°–¢–í–û –û–¢–ó–´–í–û–í
                    try:
                        reviews_selectors = [
                            ".p6b3_0_2-a4 span[style*='color:var(--textSecondary)']",  # –û—Ç–∑—ã–≤—ã
                            "span[style*='color:var(--textSecondary)']",  # –ü–æ —Ü–≤–µ—Ç—É
                            "//span[contains(text(), '–æ—Ç–∑—ã–≤')]"  # –ü–æ —Ç–µ–∫—Å—Ç—É
                        ]

                        for reviews_selector in reviews_selectors:
                            try:
                                if reviews_selector.startswith("//"):
                                    reviews_elems = card.find_elements(By.XPATH, reviews_selector)
                                else:
                                    reviews_elems = card.find_elements(By.CSS_SELECTOR, reviews_selector)

                                for elem in reviews_elems:
                                    text = elem.text.strip()
                                    if '–æ—Ç–∑—ã–≤' in text.lower():
                                        product_data['reviews_count'] = text
                                        break
                                if product_data.get('reviews_count'):
                                    break
                            except:
                                continue

                        if not product_data.get('reviews_count'):
                            product_data['reviews_count'] = ''

                    except Exception as e:
                        logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –æ—Ç–∑—ã–≤–æ–≤: {e}")
                        product_data['reviews_count'] = ''

                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–≤–∞—Ä —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ
                    if product_data.get('name'):
                        products.append(product_data)
                        logging.debug(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Ç–æ–≤–∞—Ä: {product_data['name'][:50]}...")

                except Exception as e:
                    logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–∞: {e}")
                    continue

            logging.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–ø–∞—Ä—Å–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(products)}")
            return products

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Ç–æ–≤–∞—Ä–æ–≤: {str(e)}")
            return []

    def click_shop_button(self) -> bool:
        """–ö–ª–∏–∫ –ø–æ –∫–Ω–æ–ø–∫–µ '–ú–∞–≥–∞–∑–∏–Ω' –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ - –£–ü–†–û–©–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
        try:
            logging.info("üõçÔ∏è –ò—â–µ–º –∫–Ω–æ–ø–∫—É '–ú–∞–≥–∞–∑–∏–Ω'...")
            self.take_screenshot("before_shop_button")

            # –û—Å–Ω–æ–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∫–Ω–æ–ø–∫–∏ "–ú–∞–≥–∞–∑–∏–Ω"
            shop_selectors = [
                "//div[@title='–ú–∞–≥–∞–∑–∏–Ω']",
                "//div[contains(@class, 'b5_4_7-b0') and contains(text(), '–ú–∞–≥–∞–∑–∏–Ω')]",
                "//div[contains(text(), '–ú–∞–≥–∞–∑–∏–Ω') and contains(@class, 'b5_4_7')]",
            ]

            for selector in shop_selectors:
                try:
                    elements = self.driver.find_elements(By.XPATH, selector)
                    logging.info(f"üîç –ü–æ–∏—Å–∫ –ø–æ '{selector}': –Ω–∞–π–¥–µ–Ω–æ {len(elements)}")

                    for el in elements:
                        if el.is_displayed() and el.is_enabled():
                            logging.info(f"üéØ –ù–∞—à–ª–∏ –∫–Ω–æ–ø–∫—É: {selector}")

                            # –ü—Ä–æ–∫—Ä—É—á–∏–≤–∞–µ–º –∏ –∫–ª–∏–∫–∞–µ–º
                            self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", el)
                            time.sleep(1)

                            try:
                                el.click()
                            except:
                                self.driver.execute_script("arguments[0].click();", el)

                            # –ñ–¥–µ–º –æ—Ç–∫—Ä—ã—Ç–∏—è –º–æ–¥–∞–ª–∫–∏
                            time.sleep(3)
                            self.take_screenshot("after_shop_click")

                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –æ—Ç–∫—Ä—ã–ª–∞—Å—å –ª–∏ –º–æ–¥–∞–ª–∫–∞
                            if self.check_modal_opened():
                                logging.info("‚úÖ –ú–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ —É—Å–ø–µ—à–Ω–æ –æ—Ç–∫—Ä—ã—Ç–æ")
                                return True
                            else:
                                logging.warning("‚ö†Ô∏è –ö–Ω–æ–ø–∫–∞ –Ω–∞–∂–∞—Ç–∞, –Ω–æ –º–æ–¥–∞–ª–∫–∞ –Ω–µ –æ—Ç–∫—Ä—ã–ª–∞—Å—å")
                                return False

                except Exception as e:
                    logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º {selector}: {e}")
                    continue

            logging.warning("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∫–Ω–æ–ø–∫—É '–ú–∞–≥–∞–∑–∏–Ω'")
            return False

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∫–ª–∏–∫–∞ –ø–æ –∫–Ω–æ–ø–∫–µ –º–∞–≥–∞–∑–∏–Ω–∞: {e}")
            return False

    def check_modal_opened(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —á—Ç–æ –º–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ –æ—Ç–∫—Ä—ã–ª–æ—Å—å"""
        try:
            modal_indicators = [
                "div[data-widget='modalLayout']",
                ".vue-portal-target",
                "//div[contains(text(), '–û –º–∞–≥–∞–∑–∏–Ω–µ')]"
            ]

            for selector in modal_indicators:
                try:
                    if selector.startswith("//"):
                        elements = self.driver.find_elements(By.XPATH, selector)
                    else:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    if elements and any(el.is_displayed() for el in elements):
                        logging.info(f"‚úÖ –ú–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ: {selector}")
                        return True
                except:
                    continue

            return False
        except Exception as e:
            logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ–¥–∞–ª–∫–∏: {e}")
            return False

    def extract_legal_info_from_modal(self):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞ - –û–ë–™–ï–î–ò–ù–ï–ù–ù–´–ô –ú–ï–¢–û–î"""
        try:
            logging.info("‚öñÔ∏è –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞...")

            data = {}

            # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞
            try:
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "div[data-widget='modalLayout']"))
                )
                logging.info("‚úÖ –ú–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ")
            except:
                logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–∂–¥–∞—Ç—å—Å—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞")
                return data

            self.take_screenshot("modal_content")

            # 1. –ü–∞—Ä—Å–∏–º –º–µ—Ç—Ä–∏–∫–∏ –º–∞–≥–∞–∑–∏–Ω–∞
            metrics_data = self.extract_metrics_from_modal()
            data.update(metrics_data)

            # 2. –ü–∞—Ä—Å–∏–º —é—Ä–∏–¥–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            legal_data = self.extract_legal_text_from_modal()
            data.update(legal_data)

            logging.info(f"‚úÖ –í—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –º–æ–¥–∞–ª–∫–∏ –∏–∑–≤–ª–µ—á–µ–Ω—ã: {data}")
            return data

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –º–æ–¥–∞–ª–∫–∏: {e}")
            return {}

    def extract_metrics_from_modal(self):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∏–∑ –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞"""
        data = {}

        try:
            # –ò—â–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏
            metric_rows = self.driver.find_elements(
                By.CSS_SELECTOR,
                "div[data-widget='cellList'] .b35_3_13-a"
            )

            logging.info(f"üìä –ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–æ–∫ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏: {len(metric_rows)}")

            for row in metric_rows:
                try:
                    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
                    name_elem = row.find_elements(By.CSS_SELECTOR, ".b35_3_13-a9")
                    if not name_elem:
                        continue

                    metric_name = name_elem[0].text.strip()
                    if not metric_name:
                        continue

                    # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
                    value_elem = row.find_elements(By.CSS_SELECTOR, ".b5_4_7-b0")
                    value = value_elem[0].text.strip() if value_elem else ""
                    value_title = value_elem[0].get_attribute('title') if value_elem else ""
                    final_value = value or value_title

                    logging.info(f"üìä –ú–µ—Ç—Ä–∏–∫–∞: '{metric_name}' = '{final_value}'")

                    # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º —Å –Ω–∞—à–∏–º–∏ –ø–æ–ª—è–º–∏
                    if any(word in metric_name.lower() for word in ['–∑–∞–∫–∞–∑', '–∑–∞–∫–∞–∑–æ–≤']):
                        data['–ó–∞–∫–∞–∑—ã'] = final_value
                    elif any(word in metric_name.lower() for word in ['—Ä–∞–±–æ—Ç–∞–µ—Ç', 'ozon']):
                        data['–°—Ä–æ–∫_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏'] = final_value
                    elif any(word in metric_name.lower() for word in ['–æ—Ü–µ–Ω–∫', '—Ä–µ–π—Ç–∏–Ω–≥', '—Å—Ä–µ–¥–Ω—è—è']):
                        data['–†–µ–π—Ç–∏–Ω–≥'] = final_value
                    elif any(word in metric_name.lower() for word in ['–æ—Ç–∑—ã–≤', '–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ']):
                        data['–û—Ç–∑—ã–≤—ã'] = final_value

                except Exception as e:
                    logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏ –º–µ—Ç—Ä–∏–∫–∏: {e}")
                    continue

        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –º–µ—Ç—Ä–∏–∫: {e}")

        return data

    def extract_legal_text_from_modal(self):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞"""
        data = {}

        try:
            # –ò—â–µ–º –±–ª–æ–∫ —Å —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            legal_selectors = [
                "div[data-widget='textBlock'] .tsBody400Small",
                ".d0q_11 .tsBody400Small",
                "//span[@class='tsBody400Small']"
            ]

            legal_text = ""
            for selector in legal_selectors:
                try:
                    if selector.startswith("//"):
                        elements = self.driver.find_elements(By.XPATH, selector)
                    else:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    for element in elements:
                        if element.is_displayed():
                            text = element.text.strip()
                            if text and len(text) > 10:
                                legal_text = text
                                logging.info(f"‚úÖ –ù–∞–π–¥–µ–Ω —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–π —Ç–µ–∫—Å—Ç: {text}")
                                break

                    if legal_text:
                        break

                except Exception as e:
                    logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º {selector}: {e}")
                    continue

            # –ü–∞—Ä—Å–∏–º —é—Ä–∏–¥–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            if legal_text:
                lines = legal_text.split('\n')

                # –ù–∞–∑–≤–∞–Ω–∏–µ —é—Ä–ª–∏—Ü–∞ (–ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞)
                if lines:
                    data['–ù–∞–∑–≤–∞–Ω–∏–µ_—é—Ä_–ª–∏—Ü–∞'] = lines[0].strip()
                    logging.info(f"‚úÖ –ù–∞–∑–≤–∞–Ω–∏–µ —é—Ä–ª–∏—Ü–∞: {data['–ù–∞–∑–≤–∞–Ω–∏–µ_—é—Ä_–ª–∏—Ü–∞']}")

                # –ò—â–µ–º –û–ì–†–ù –∏ –ò–ù–ù
                import re

                # –û–ì–†–ù (13 —Ü–∏—Ñ—Ä)
                ogrn_match = re.search(r'\b\d{13}\b', legal_text)
                if ogrn_match:
                    data['–û–ì–†–ù'] = ogrn_match.group()
                else:
                    ogrn_alt = re.search(r'–û–ì–†–ù\s*[:\-]?\s*(\d{13})', legal_text, re.IGNORECASE)
                    if ogrn_alt:
                        data['–û–ì–†–ù'] = ogrn_alt.group(1)

                # –ò–ù–ù (10 –∏–ª–∏ 12 —Ü–∏—Ñ—Ä)
                inn_match = re.search(r'\b\d{10,12}\b', legal_text)
                if inn_match:
                    data['–ò–ù–ù'] = inn_match.group()
                else:
                    inn_alt = re.search(r'–ò–ù–ù\s*[:\-]?\s*(\d{10,12})', legal_text, re.IGNORECASE)
                    if inn_alt:
                        data['–ò–ù–ù'] = inn_alt.group(1)

                # –ê–≤—Ç–æ-–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ —à–∞–±–ª–æ–Ω–∞–º
                if not data.get('–û–ì–†–ù') and not data.get('–ò–ù–ù'):
                    numbers = re.findall(r'\b\d{10,13}\b', legal_text)
                    for num in numbers:
                        if len(num) == 13 and not data.get('–û–ì–†–ù'):
                            data['–û–ì–†–ù'] = num
                        elif len(num) in [10, 12] and not data.get('–ò–ù–ù'):
                            data['–ò–ù–ù'] = num

                logging.info(f"‚úÖ –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ: –û–ì–†–ù={data.get('–û–ì–†–ù')}, –ò–ù–ù={data.get('–ò–ù–ù')}")

        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —é—Ä–∏–¥–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é: {e}")

        return data

    def close_modal(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞ - –£–ü–†–û–©–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
        try:
            logging.info("üîí –ó–∞–∫—Ä—ã–≤–∞–µ–º –º–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ...")
            self.take_screenshot("before_modal_close")

            # –û—Å–Ω–æ–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∑–∞–∫—Ä—ã—Ç–∏—è
            close_selectors = [
                "//button[contains(., '–ü–æ–Ω—è—Ç–Ω–æ')]",
                "button[data-widget='modalClose']",
                ".b65_4_11-b1",  # –ö—Ä–µ—Å—Ç–∏–∫
                "//button[contains(@class, 'b25_5_1-a0')]"
            ]

            for selector in close_selectors:
                try:
                    if selector.startswith("//"):
                        elements = self.driver.find_elements(By.XPATH, selector)
                    else:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    for btn in elements:
                        if btn.is_displayed() and btn.is_enabled():
                            self.driver.execute_script("arguments[0].click();", btn)
                            time.sleep(2)
                            self.take_screenshot("after_modal_close")
                            logging.info("‚úÖ –ú–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ –∑–∞–∫—Ä—ã—Ç–æ")
                            return True
                except:
                    continue

            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –∫–ª–∏–∫ –ø–æ overlay
            try:
                overlay = self.driver.find_element(By.CSS_SELECTOR, ".b65_4_11-a0")
                self.driver.execute_script("arguments[0].click();", overlay)
                time.sleep(1)
                logging.info("‚úÖ –ú–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ –∑–∞–∫—Ä—ã—Ç–æ —á–µ—Ä–µ–∑ overlay")
                return True
            except:
                pass

            logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–∫—Ä—ã—Ç—å –º–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ")
            return False

        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞: {e}")
            return False

    def extract_shop_info(self):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¢–û–õ–¨–ö–û –Ω–∞–∑–≤–∞–Ω–∏—è –º–∞–≥–∞–∑–∏–Ω–∞ —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            data = {}

            # –ü–û–ò–°–ö –ù–ê–ó–í–ê–ù–ò–Ø –ú–ê–ì–ê–ó–ò–ù–ê
            try:
                main_page_name_selectors = [
                    "h1.seller-name",
                    ".seller-title",
                    "[data-widget='webSellerName']",
                    "//h1[contains(@class, 'seller')]",
                    "//div[contains(@class, 'seller-header')]//h1",
                    "//span[contains(@class, 'tsHeadline600Large')]",
                    ".bq03_0_2-a.bq03_0_2-a4.bq03_0_2-a5.h5n_19 span.tsHeadline600Large",
                    "//div[contains(@class, 'h5n_19')]//span"
                ]

                shop_name_found = False
                for selector in main_page_name_selectors:
                    try:
                        if selector.startswith("//"):
                            elements = self.driver.find_elements(By.XPATH, selector)
                        else:
                            elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                        for element in elements:
                            if element.is_displayed() and element.text.strip():
                                shop_name = element.text.strip()
                                if len(shop_name) > 2:
                                    data['–ù–∞–∑–≤–∞–Ω–∏–µ'] = shop_name
                                    logging.info(f"‚úÖ –ù–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞ –Ω–∞–π–¥–µ–Ω–æ –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {data['–ù–∞–∑–≤–∞–Ω–∏–µ']}")
                                    shop_name_found = True
                                    break

                        if shop_name_found:
                            break

                    except Exception as e:
                        continue

                if not shop_name_found:
                    logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –Ω–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞ —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã")
                    data['–ù–∞–∑–≤–∞–Ω–∏–µ'] = ''

            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –º–∞–≥–∞–∑–∏–Ω–∞: {e}")
                data['–ù–∞–∑–≤–∞–Ω–∏–µ'] = ''

            return data

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–∞–≥–∞–∑–∏–Ω–µ: {e}")
            return {'–ù–∞–∑–≤–∞–Ω–∏–µ': ''}

    def parse_seller(self, seller_id):
        """–ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–¥–∞–≤—Ü–∞ - –£–õ–£–ß–®–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
        url = f"https://www.ozon.ru/seller/{seller_id}"
        seller_data = {'URL': url}
        html_paths = []
        max_attempts = 3
        attempt = 1

        while attempt <= max_attempts:
            try:
                logging.info(f"üöÄ –ü–æ–ø—ã—Ç–∫–∞ {attempt}/{max_attempts} –¥–ª—è –ø—Ä–æ–¥–∞–≤—Ü–∞ {seller_id}")
                self.take_screenshot(f"start_attempt_{attempt}")

                # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                if not self.load_seller_page(url, attempt):
                    if self.retry_after_blocking(seller_id, attempt, max_attempts):
                        attempt += 1
                        continue
                    else:
                        break

                # –û—Å–Ω–æ–≤–Ω–æ–π –ø–∞—Ä—Å–∏–Ω–≥
                parsing_success = self.parse_seller_data(seller_id, seller_data, html_paths)

                if parsing_success:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    seller_data['Html_–ø—É—Ç—å'] = "; ".join(html_paths)
                    if self.save_to_csv(seller_data):
                        logging.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –ø—Ä–æ–¥–∞–≤–µ—Ü {seller_id}")
                        return seller_data
                    else:
                        logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {seller_id}")
                        return None
                else:
                    logging.warning(f"‚ö†Ô∏è –ù–µ–ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {seller_id}, –ø–æ–ø—ã—Ç–∫–∞ {attempt}")

                # –ï—Å–ª–∏ –¥–æ—à–ª–∏ —Å—é–¥–∞, –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞
                if attempt < max_attempts:
                    if self.retry_after_error(seller_id, attempt):
                        attempt += 1
                        continue
                    else:
                        break
                else:
                    logging.error(f"‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–æ–≤–∞–ª–∏–ª–∏—Å—å –¥–ª—è {seller_id}")
                    break

            except Exception as e:
                logging.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt}: {e}")
                if not self.handle_critical_error(seller_id, attempt, max_attempts):
                    break
                attempt += 1

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ, —á—Ç–æ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å
        return self.finalize_parsing(seller_data, html_paths)

    def load_seller_page(self, url, attempt):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø—Ä–æ–¥–∞–≤—Ü–∞"""
        try:
            self.driver.set_page_load_timeout(30)
            time.sleep(random.uniform(2, 4))

            logging.info(f"üåê –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É: {url}")
            self.driver.get(url)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
            if self.check_and_handle_blocking():
                logging.warning(f"üõë –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt}")
                return False

            time.sleep(random.uniform(2, 4))
            self.random_mouse_movements()
            return True

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
            return False

    def parse_seller_data(self, seller_id, seller_data, html_paths):
        """–û—Å–Ω–æ–≤–Ω–æ–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–æ–¥–∞–≤—Ü–∞"""
        try:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é HTML —Å—Ç—Ä–∞–Ω–∏—Ü—É
            main_html_path = self.save_html_page(seller_id, "main_")
            html_paths.append(main_html_path)
            self.take_screenshot("page_loaded")

            # 1. –ù–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞
            if not self.parse_shop_name(seller_data):
                logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –Ω–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞")

            # 2. –¢–æ–≤–∞—Ä—ã –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
            if not self.parse_products(seller_data):
                logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–æ–≤–∞—Ä—ã")

            # 3. –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞
            if not self.parse_legal_info(seller_id, seller_data, html_paths):
                logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —é—Ä–∏–¥–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é")

            logging.info(f"‚úÖ –û—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑–≤–ª–µ—á–µ–Ω—ã –¥–ª—è {seller_id}")
            return True

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return False

    def parse_shop_name(self, seller_data):
        """–ü–∞—Ä—Å–∏–Ω–≥ –Ω–∞–∑–≤–∞–Ω–∏—è –º–∞–≥–∞–∑–∏–Ω–∞"""
        try:
            shop_name_data = self.extract_shop_info()
            seller_data.update(shop_name_data)

            name = seller_data.get('–ù–∞–∑–≤–∞–Ω–∏–µ', '')
            if name:
                logging.info(f"‚úÖ –ù–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞: {name}")
                return True
            else:
                seller_data['–ù–∞–∑–≤–∞–Ω–∏–µ'] = ''
                return False

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏—è: {e}")
            seller_data['–ù–∞–∑–≤–∞–Ω–∏–µ'] = ''
            return False

    def parse_products(self, seller_data):
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ç–æ–≤–∞—Ä–æ–≤"""
        try:
            products = self.extract_products_from_main_page()
            seller_data['–ö–æ–ª-–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤_–Ω–∞_—Å—Ç—Ä–∞–Ω–∏—Ü–µ'] = len(products)
            seller_data['–¢–æ–≤–∞—Ä—ã_JSON'] = json.dumps(products, ensure_ascii=False, indent=2)

            logging.info(f"‚úÖ –°–ø–∞—Ä—Å–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(products)}")
            return len(products) > 0

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–æ–≤–∞—Ä–æ–≤: {e}")
            seller_data['–ö–æ–ª-–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤_–Ω–∞_—Å—Ç—Ä–∞–Ω–∏—Ü–µ'] = 0
            seller_data['–¢–æ–≤–∞—Ä—ã_JSON'] = '[]'
            return False

    def parse_legal_info(self, seller_id, seller_data, html_paths):
        """–ü–∞—Ä—Å–∏–Ω–≥ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
        try:
            if not self.click_shop_button():
                logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –º–æ–¥–∞–ª–∫—É")
                return False

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞
            shop_html_path = self.save_html_page(seller_id, "shop_")
            html_paths.append(shop_html_path)

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –º–æ–¥–∞–ª–∫–∏
            legal_info = self.extract_legal_info_from_modal()
            seller_data.update(legal_info)

            # –ó–∞–∫—Ä—ã–≤–∞–µ–º –º–æ–¥–∞–ª–∫—É
            self.close_modal()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ —Ö–æ—Ç—å –∫–∞–∫–∏–µ-—Ç–æ –¥–∞–Ω–Ω—ã–µ
            legal_fields = ['–û–ì–†–ù', '–ò–ù–ù', '–ù–∞–∑–≤–∞–Ω–∏–µ_—é—Ä_–ª–∏—Ü–∞', '–û—Ç–∑—ã–≤—ã', '–†–µ–π—Ç–∏–Ω–≥', '–°—Ä–æ–∫_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏']
            extracted_fields = [field for field in legal_fields if seller_data.get(field)]

            logging.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω—ã —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ: {len(extracted_fields)} –ø–æ–ª–µ–π")
            return len(extracted_fields) > 0

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–∞–ª—å–Ω—ã–º –æ–∫–Ω–æ–º: {e}")
            return False

    def retry_after_blocking(self, seller_id, attempt, max_attempts):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –∏ –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞"""
        if attempt < max_attempts:
            delay = random.uniform(20, 40)
            logging.info(f"‚è≥ –ó–∞–¥–µ—Ä–∂–∫–∞ {delay:.1f} —Å–µ–∫ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π")
            time.sleep(delay)
            return True
        else:
            logging.error(f"‚ùå –í—Å–µ {max_attempts} –ø–æ–ø—ã—Ç–æ–∫ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è {seller_id}")
            return False

    def retry_after_error(self, seller_id, attempt):
        """–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ –ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏"""
        delay = random.uniform(10, 20)
        logging.info(f"‚è≥ –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ {delay:.1f} —Å–µ–∫")
        time.sleep(delay)
        return True

    def handle_critical_error(self, seller_id, attempt, max_attempts):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–æ–∫"""
        self.take_screenshot(f"critical_error_attempt_{attempt}")

        if attempt < max_attempts:
            delay = random.uniform(15, 25)
            logging.info(f"‚è≥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞, –ø–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {delay:.1f} —Å–µ–∫")
            time.sleep(delay)
            return True
        else:
            logging.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –Ω–∞ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–∫–∞—Ö –¥–ª—è {seller_id}")
            return False

    def finalize_parsing(self, seller_data, html_paths):
        """–§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏ –∫ HTML –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
            if html_paths:
                seller_data['Html_–ø—É—Ç—å'] = "; ".join(html_paths)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ, —á—Ç–æ –µ—Å—Ç—å
            if seller_data:
                self.save_to_csv(seller_data)
                logging.info("üíæ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã (—á–∞—Å—Ç–∏—á–Ω—ã–µ)")
                return seller_data
            else:
                logging.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –Ω–∏–∫–∞–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö")
                return None

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            return None

    def check_and_handle_blocking(self) -> bool:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
            blocking_indicators = [
                "//h1[contains(text(), '–î–æ—Å—Ç—É–ø –æ–≥—Ä–∞–Ω–∏—á–µ–Ω')]",
                "//h1[contains(text(), '–û–π!')]",
                "//title[contains(text(), '–î–æ—Å—Ç—É–ø')]",
                "//div[contains(text(), '–ø—Ä–æ–≤–µ—Ä–∫—É')]",
                "//div[contains(text(), '–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç')]",
                "iframe[src*='captcha']",
                "//input[@name='captcha']"
            ]

            for indicator in blocking_indicators:
                try:
                    elements = self.driver.find_elements(By.XPATH, indicator)
                    if elements:
                        logging.warning(f"üõë –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞: {indicator}")
                        self.take_screenshot("blocked")
                        return True
                except:
                    continue

            return False

        except Exception as e:
            logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏: {e}")
            return False

    def random_mouse_movements(self):
        """–°–ª—É—á–∞–π–Ω—ã–µ –¥–≤–∏–∂–µ–Ω–∏—è –º—ã—à—å—é –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ —á–µ–ª–æ–≤–µ–∫–∞"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã –æ–∫–Ω–∞
            window_size = self.driver.get_window_size()
            width = window_size['width']
            height = window_size['height']

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
            x1 = random.randint(100, width - 100)
            y1 = random.randint(100, height - 100)
            x2 = random.randint(100, width - 100)
            y2 = random.randint(100, height - 100)

            # –°–æ–∑–¥–∞–µ–º ActionChains –¥–ª—è –ø–ª–∞–≤–Ω–æ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è
            actions = webdriver.ActionChains(self.driver)

            # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –º—ã—à—å—é –ø–æ —Å–ª—É—á–∞–π–Ω–æ–π —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
            actions.move_by_offset(x1, y1).pause(random.uniform(0.1, 0.3))
            actions.move_by_offset(x2 - x1, y2 - y1).pause(random.uniform(0.1, 0.3))
            actions.perform()

            # –°–ª—É—á–∞–π–Ω—ã–π —Å–∫—Ä–æ–ª–ª
            scroll_pixels = random.randint(200, 800)
            self.driver.execute_script(f"window.scrollBy(0, {scroll_pixels});")
            time.sleep(random.uniform(0.5, 1.5))

        except Exception as e:
            logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–≤–∏–∂–µ–Ω–∏–∏ –º—ã—à—å—é: {e}")

    def close(self):
        """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ –¥—Ä–∞–π–≤–µ—Ä–∞ –∏ –æ—á–∏—Å—Ç–∫–∞"""
        if self.driver:
            try:
                self.driver.quit()
            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –¥—Ä–∞–π–≤–µ—Ä–∞: {e}")
            self.driver = None

        if self.chrome_temp_dir and os.path.exists(self.chrome_temp_dir):
            try:
                shutil.rmtree(self.chrome_temp_dir)
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é: {e}")


def callback(ch, method, properties, body):
    seller_id = body.decode()
    logging.info(f"üéØ –ü–æ–ª—É—á–µ–Ω ID –ø—Ä–æ–¥–∞–≤—Ü–∞: {seller_id}")

    def task_wrapper():
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—É—é –∑–∞–¥–µ—Ä–∂–∫—É –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏
        delay = random.uniform(1, 10)
        logging.info(f"‚è≥ –°–ª—É—á–∞–π–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π {seller_id}: {delay:.2f} —Å–µ–∫")
        time.sleep(delay)

        parse_task(seller_id)
        with lock:
            ch.basic_ack(delivery_tag=method.delivery_tag)

    executor.submit(task_wrapper)


def start_consumer():
    while True:
        try:
            connection_params = pika.ConnectionParameters(
                host=os.getenv('RABBITMQ_HOST', 'rabbitmq'),
                port=5672,
                credentials=pika.PlainCredentials(
                    os.getenv('RABBITMQ_USER', 'guest'),
                    os.getenv('RABBITMQ_PASS', 'guest')
                ),
                heartbeat=600,
                blocked_connection_timeout=300,
                connection_attempts=10,
                retry_delay=5
            )

            connection = pika.BlockingConnection(connection_params)
            channel = connection.channel()

            # –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –û–ë–™–Ø–í–õ–ï–ù–ò–ï –û–ß–ï–†–ï–î–ò
            channel.queue_declare(
                queue='seller_ids',
                durable=True,
                passive=True  # –¢–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ, –Ω–µ —Å–æ–∑–¥–∞–µ–º –∑–∞–Ω–æ–≤–æ
            )

            channel.basic_qos(prefetch_count=1)
            channel.basic_consume(
                queue='seller_ids',
                on_message_callback=callback,
                auto_ack=False
            )

            logging.info("üîÑ –û–∂–∏–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ RabbitMQ...")
            channel.start_consuming()

        except pika.exceptions.AMQPConnectionError as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ RabbitMQ: {e}")
            time.sleep(10)
        except Exception as e:
            logging.error(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
            time.sleep(10)


if __name__ == "__main__":
    start_consumer()