import csv
import logging
import random
import time
import os
import sys
import tempfile
import shutil
import json
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium_stealth import stealth
from webdriver_manager.chrome import ChromeDriverManager
from webdriver_manager.core.os_manager import ChromeType
import pika

# –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫–∏ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ
os.makedirs("/app/logs", exist_ok=True)
os.makedirs("/app/data", exist_ok=True)
os.makedirs("/app/screenshots", exist_ok=True)
os.makedirs("/app/html", exist_ok=True)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/app/logs/parser.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)


class OzonSellerParser:
    def __init__(self):
        self.instance_id = os.getenv('HOSTNAME', f"parser-{random.randint(1000, 9999)}")
        self.request_count = 0
        self.driver = None
        self.wait = None
        self.current_proxy = None
        self.proxy_list = []
        self.proxy_rotation_count = int(os.getenv('PROXY_ROTATION_COUNT', 3))
        self.proxy_timeout = int(os.getenv('PROXY_ROTATION_TIMEOUT', 30))

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏
        proxy_list_str = os.getenv('PROXY_LIST', '')
        if proxy_list_str:
            self.proxy_list = [p.strip() for p in proxy_list_str.split(',') if p.strip()]

        # –£–Ω–∏–∫–∞–ª—å–Ω–∞—è –≤—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è Chrome
        self.chrome_temp_dir = tempfile.mkdtemp()
        logging.info(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞—Ä—Å–µ—Ä–∞ {self.instance_id}, –ø—Ä–æ—Ñ–∏–ª—å: {self.chrome_temp_dir}")

        try:
            self.setup_driver()
            self.wait = WebDriverWait(self.driver, 15)

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CSV
            self.data_dir = "/app/data"
            os.makedirs(self.data_dir, exist_ok=True)
            self.csv_file = f"{self.data_dir}/sellers_{self.instance_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
            self.init_csv()
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø–∞—Ä—Å–µ—Ä–∞: {e}", exc_info=True)
            self.close()
            raise

    def rotate_proxy(self):
        """–†–æ—Ç–∞—Ü–∏—è –ø—Ä–æ–∫—Å–∏ –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ –¥—Ä–∞–π–≤–µ—Ä–∞"""
        if not self.proxy_list or len(self.proxy_list) <= 1:
            return False

        try:
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –ø—Ä–æ–∫—Å–∏ –ø–æ –∫—Ä—É–≥—É
            self.current_proxy_index = (self.current_proxy_index + 1) % len(self.proxy_list)
            new_proxy = self.proxy_list[self.current_proxy_index]

            old_proxy = self.current_proxy
            self.current_proxy = new_proxy
            self.requests_per_proxy = 0  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫

            logging.info(
                f"üîÑ –†–æ—Ç–∏—Ä—É–µ–º –ø—Ä–æ–∫—Å–∏ [{self.current_proxy_index + 1}/{len(self.proxy_list)}]: {old_proxy} -> {new_proxy}")

            # –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º –¥—Ä–∞–π–≤–µ—Ä —Å –Ω–æ–≤—ã–º –ø—Ä–æ–∫—Å–∏
            if self.driver:
                self.driver.quit()
                time.sleep(2)

            self.setup_driver()
            self.wait = WebDriverWait(self.driver, 15)

            logging.info("‚úÖ –ü—Ä–æ–∫—Å–∏ —É—Å–ø–µ—à–Ω–æ —Å–º–µ–Ω–µ–Ω")
            return True

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–æ—Ç–∞—Ü–∏–∏ –ø—Ä–æ–∫—Å–∏: {e}")
            # –ü—Ä–æ–±—É–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–∞–±–æ—Ç—É —Å —Ç–µ–∫—É—â–∏–º –ø—Ä–æ–∫—Å–∏
            try:
                if self.driver:
                    self.driver.quit()
                self.setup_driver()
                self.wait = WebDriverWait(self.driver, 15)
            except:
                pass
            return False

    def setup_driver(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ Chrome –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ Docker —Å headless, stealth –∏ –ø—Ä–æ–∫—Å–∏"""
        chrome_options = Options()

        # === –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø—Ü–∏–∏ –¥–ª—è Docker ===
        chrome_options.add_argument("--headless=new")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--disable-extensions")
        chrome_options.add_argument("--disable-setuid-sandbox")
        chrome_options.add_argument("--disable-software-rasterizer")
        chrome_options.add_argument("--disable-ipc-flooding-protection")
        chrome_options.add_argument("--disable-background-timer-throttling")
        chrome_options.add_argument("--disable-backgrounding-occluded-windows")
        chrome_options.add_argument("--disable-renderer-backgrounding")
        chrome_options.add_argument("--disable-features=VizDisplayCompositor")

        # === –†–∞–∑–º–µ—Ä –æ–∫–Ω–∞ ===
        chrome_options.add_argument("--window-size=1366,768")

        # === –ù–ê–°–¢–†–û–ô–ö–ê –ü–†–û–ö–°–ò ===
        use_proxies = os.getenv('USE_PROXIES', 'false').lower() == 'true'
        proxy_list_str = os.getenv('PROXY_LIST', '')

        if use_proxies and proxy_list_str:
            self.proxy_list = [p.strip() for p in proxy_list_str.split(',') if p.strip()]

            if self.proxy_list:
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏–Ω–¥–µ–∫—Å –ø—Ä–æ–∫—Å–∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ
                if not hasattr(self, 'current_proxy_index'):
                    self.current_proxy_index = 0
                    self.requests_per_proxy = 0

                # –ë–µ—Ä–µ–º —Ç–µ–∫—É—â–∏–π –ø—Ä–æ–∫—Å–∏ –ø–æ –∏–Ω–¥–µ–∫—Å—É (–∞ –Ω–µ —Å–ª—É—á–∞–π–Ω—ã–π)
                current_proxy = self.proxy_list[self.current_proxy_index]
                chrome_options.add_argument(f'--proxy-server={current_proxy}')
                self.current_proxy = current_proxy

                logging.info(
                    f"üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏ [{self.current_proxy_index + 1}/{len(self.proxy_list)}]: {current_proxy}")
            else:
                logging.warning("‚ö†Ô∏è PROXY_LIST –ø—É—Å—Ç–æ–π, —Ä–∞–±–æ—Ç–∞–µ–º –±–µ–∑ –ø—Ä–æ–∫—Å–∏")
                self.current_proxy = None
                self.proxy_list = []
        else:
            logging.info("üîå –ü—Ä–æ–∫—Å–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö")
            self.current_proxy = None
            self.proxy_list = []

        # === –£–ª—É—á—à–µ–Ω–Ω—ã–µ stealth –æ–ø—Ü–∏–∏ ===
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_argument("--disable-features=UserAgentClientHint")
        chrome_options.add_argument("--no-first-run")
        chrome_options.add_argument("--no-default-browser-check")
        chrome_options.add_argument("--disable-component-extensions-with-background-pages")
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation", "enable-logging"])
        chrome_options.add_experimental_option('useAutomationExtension', False)

        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å
        chrome_options.add_argument(f"--user-data-dir={self.chrome_temp_dir}")

        # –°–ª—É—á–∞–π–Ω—ã–π User-Agent
        user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/121.0.0.0",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15"
        ]
        chrome_options.add_argument(f"--user-agent={random.choice(user_agents)}")

        # === –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞ ===
        try:
            service = Service(ChromeDriverManager(chrome_type=ChromeType.GOOGLE).install())
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞: {e}", exc_info=True)
            raise

        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ selenium-stealth
        try:
            stealth(
                self.driver,
                languages=["ru-RU", "ru", "en-US", "en"],
                vendor="Google Inc.",
                platform="Win32",
                webgl_vendor="Intel Inc.",
                renderer="Intel Iris OpenGL Engine",
                fix_hairline=True,
                run_on_insecure_origins=False
            )
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è selenium-stealth: {e}")

    def init_csv(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CSV —Ñ–∞–π–ª–∞"""
        headers = [
            'URL', '–Ω–∞–∑–≤–∞–Ω–∏–µ', 'Html', '–û–ì–†–ù', '–ò–ù–ù', '–ù–∞–∑–≤–∞–Ω–∏–µ —é—Ä –ª–∏—Ü–∞',
            '–ö–æ–ª-–≤–æ –æ—Ç–∑—ã–≤–æ–≤', '—Ä–µ–π—Ç–∏–Ω–≥', '–°—Ä–æ–∫ —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏', '–¢–æ–≤–∞—Ä—ã'
        ]
        try:
            with open(self.csv_file, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                writer.writerow(headers)
            logging.info(f"‚úÖ –°–æ–∑–¥–∞–Ω CSV —Ñ–∞–π–ª: {self.csv_file}")
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è CSV: {e}", exc_info=True)

    def save_to_csv(self, data):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ CSV"""
        try:
            with open(self.csv_file, 'a', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                writer.writerow([
                    data.get('URL', ''),
                    data.get('–ù–∞–∑–≤–∞–Ω–∏–µ', ''),
                    data.get('Html_–ø—É—Ç—å', ''),
                    data.get('–û–ì–†–ù', ''),
                    data.get('–ò–ù–ù', ''),
                    data.get('–ù–∞–∑–≤–∞–Ω–∏–µ_—é—Ä_–ª–∏—Ü–∞', ''),
                    data.get('–û—Ç–∑—ã–≤—ã', ''),
                    data.get('–†–µ–π—Ç–∏–Ω–≥', ''),
                    data.get('–°—Ä–æ–∫_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏', ''),
                    data.get('–¢–æ–≤–∞—Ä—ã_JSON', '')
                ])
                f.flush()
                os.fsync(f.fileno())
            logging.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ CSV")
            return True
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ CSV: {e}", exc_info=True)
            return False

    def save_html_page(self, seller_id, prefix=""):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            html_path = f"/app/html/{prefix}{seller_id}_{int(time.time())}.html"
            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(self.driver.page_source)
            return html_path
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å HTML: {e}")
            return ""

    def extract_products_from_main_page(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ç–æ–≤–∞—Ä–æ–≤ —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            logging.info("üõí –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Ç–æ–≤–∞—Ä–æ–≤ —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã...")

            # –ñ–¥–µ–º –ø–æ—è–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ —Å —Ç–æ–≤–∞—Ä–∞–º–∏
            try:
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located(
                        (By.CSS_SELECTOR, "div[data-widget*='paginator'], div[data-widget*='tileGrid'], div.tile-root"))
                )
            except:
                logging.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å —Ç–æ–≤–∞—Ä–∞–º–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫")
                return []

            products = []

            # ‚ö° –û–°–ù–û–í–ù–´–ï –°–ï–õ–ï–ö–¢–û–†–´ –î–õ–Ø –ö–ê–†–¢–û–ß–ï–ö –¢–û–í–ê–†–û–í ‚ö°
            # –ò—â–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ —Ä–∞–∑–Ω—ã–º —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º
            product_selectors = [
                "div.tile-root[data-index]",  # –û—Å–Ω–æ–≤–Ω–æ–π —Å–µ–ª–µ–∫—Ç–æ—Ä
                "div[data-widget*='tileGrid'] div.tile-root",  # –í–Ω—É—Ç—Ä–∏ tileGrid
                "#paginator div.tile-root",  # –í–Ω—É—Ç—Ä–∏ –ø–∞–≥–∏–Ω–∞—Ç–æ—Ä–∞
                "div[data-index]"  # –õ—é–±–æ–π —ç–ª–µ–º–µ–Ω—Ç —Å data-index
            ]

            product_cards = []
            for selector in product_selectors:
                try:
                    cards = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if cards:
                        product_cards = cards
                        logging.info(f"üì¶ –ù–∞–π–¥–µ–Ω–æ –∫–∞—Ä—Ç–æ—á–µ–∫ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ —Å–µ–ª–µ–∫—Ç–æ—Ä—É '{selector}': {len(cards)}")
                        break
                except:
                    continue

            if not product_cards:
                logging.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∫–∞—Ä—Ç–æ—á–µ–∫ —Ç–æ–≤–∞—Ä–æ–≤")
                return []

            # –ü–∞—Ä—Å–∏–º —Ç–æ–ª—å–∫–æ –≤–∏–¥–∏–º—ã–µ –∫–∞—Ä—Ç–æ—á–∫–∏ (–ø–µ—Ä–≤—ã–µ 20 –∏–ª–∏ –≤—Å–µ –≤–∏–¥–∏–º—ã–µ)
            visible_cards = [card for card in product_cards if card.is_displayed()][:20]
            logging.info(f"üéØ –ü–∞—Ä—Å–∏–º –≤–∏–¥–∏–º—ã—Ö –∫–∞—Ä—Ç–æ—á–µ–∫: {len(visible_cards)}")

            for card in visible_cards:
                try:
                    product_data = {}

                    # 1. –ù–ê–ó–í–ê–ù–ò–ï –¢–û–í–ê–†–ê
                    try:
                        # –ò—â–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –º–µ—Å—Ç–µ
                        name_selectors = [
                            ".bq03_0_2-a span.tsBody500Medium",  # –û—Å–Ω–æ–≤–Ω–æ–π —Å–µ–ª–µ–∫—Ç–æ—Ä –Ω–∞–∑–≤–∞–Ω–∏—è
                            "a[href*='/product/'] .bq03_0_2-a span",  # –í —Å—Å—ã–ª–∫–µ
                            ".tsBody500Medium",  # –ü–æ –∫–ª–∞—Å—Å—É —Ç–µ–∫—Å—Ç–∞
                            "span[class*='tsBody500']"  # –õ—é–±–æ–π span —Å —Ç–µ–∫—Å—Ç–æ–º
                        ]

                        for name_selector in name_selectors:
                            try:
                                name_elem = card.find_element(By.CSS_SELECTOR, name_selector)
                                name_text = name_elem.text.strip()
                                if name_text and len(name_text) > 5:  # –ù–∞–∑–≤–∞–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–º
                                    product_data['name'] = name_text
                                    break
                            except:
                                continue

                        if not product_data.get('name'):
                            product_data['name'] = ''

                    except Exception as e:
                        logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏—è: {e}")
                        product_data['name'] = ''

                    # 2. –¶–ï–ù–ê –¢–û–í–ê–†–ê
                    try:
                        # –û—Å–Ω–æ–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã —Ü–µ–Ω—ã
                        price_selectors = [
                            ".c35_3_8-a1.tsHeadline500Medium",  # –û—Å–Ω–æ–≤–Ω–∞—è —Ü–µ–Ω–∞
                            "span[class*='tsHeadline500Medium']",  # –¶–µ–Ω–∞ –ø–æ –∫–ª–∞—Å—Å—É
                            ".c35_3_8-a0 span",  # –í –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ —Ü–µ–Ω—ã
                            "//span[contains(text(), '‚ÇΩ')]"  # –õ—é–±–æ–π —ç–ª–µ–º–µ–Ω—Ç —Å —Å–∏–º–≤–æ–ª–æ–º —Ä—É–±–ª—è
                        ]

                        for price_selector in price_selectors:
                            try:
                                if price_selector.startswith("//"):
                                    price_elems = card.find_elements(By.XPATH, price_selector)
                                else:
                                    price_elems = card.find_elements(By.CSS_SELECTOR, price_selector)

                                for elem in price_elems:
                                    text = elem.text.strip()
                                    # –ò—â–µ–º —Ü–µ–Ω—É —Å —Å–∏–º–≤–æ–ª–æ–º —Ä—É–±–ª—è –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —Ü–∏—Ñ—Ä—ã
                                    if '‚ÇΩ' in text or (any(char.isdigit() for char in text) and len(text) <= 20):
                                        product_data['price'] = text
                                        break
                                if product_data.get('price'):
                                    break
                            except:
                                continue

                        if not product_data.get('price'):
                            product_data['price'] = ''

                    except Exception as e:
                        logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Ü–µ–Ω—ã: {e}")
                        product_data['price'] = ''

                    # 3. –°–°–´–õ–ö–ê –ù–ê –¢–û–í–ê–†
                    try:
                        link_selectors = [
                            "a[href*='/product/']",  # –û—Å–Ω–æ–≤–Ω–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ —Ç–æ–≤–∞—Ä
                            ".tile-clickable-element[href*='/product/']"  # –ö–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç
                        ]

                        for link_selector in link_selectors:
                            try:
                                link_elem = card.find_element(By.CSS_SELECTOR, link_selector)
                                href = link_elem.get_attribute('href')
                                if href and '/product/' in href:
                                    product_data['link'] = href if href.startswith(
                                        'http') else f"https://www.ozon.ru{href}"
                                    break
                            except:
                                continue

                        if not product_data.get('link'):
                            product_data['link'] = ''

                    except Exception as e:
                        logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Å—Å—ã–ª–∫–∏: {e}")
                        product_data['link'] = ''

                    # 4. –§–û–¢–û –¢–û–í–ê–†–ê
                    try:
                        img_selectors = [
                            "img.i4s_24.b95_3_3-a",
                            "img[loading='eager']",
                            "img[src*='ozon.ru']",
                            "img.b95_3_3-a"
                        ]

                        for img_selector in img_selectors:
                            try:
                                img_elem = card.find_element(By.CSS_SELECTOR, img_selector)
                                img_src = img_elem.get_attribute('src')
                                if img_src and 'ozon.ru' in img_src:
                                    product_data['image'] = img_src
                                    break
                            except:
                                continue

                        if not product_data.get('image'):
                            product_data['image'] = ''

                    except Exception as e:
                        logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Ñ–æ—Ç–æ: {e}")
                        product_data['image'] = ''

                    # 5. –†–ï–ô–¢–ò–ù–ì –¢–û–í–ê–†–ê
                    try:
                        rating_selectors = [
                            ".p6b3_0_2-a4 span[style*='color:var(--textPremium)']",  # –†–µ–π—Ç–∏–Ω–≥
                            "span[style*='color:var(--textPremium)']",  # –ü–æ —Ü–≤–µ—Ç—É
                            "//span[contains(@style, 'textPremium')]"  # XPath –ø–æ —Å—Ç–∏–ª—é
                        ]

                        for rating_selector in rating_selectors:
                            try:
                                if rating_selector.startswith("//"):
                                    rating_elems = card.find_elements(By.XPATH, rating_selector)
                                else:
                                    rating_elems = card.find_elements(By.CSS_SELECTOR, rating_selector)

                                for elem in rating_elems:
                                    text = elem.text.strip()
                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Ä–µ–π—Ç–∏–Ω–≥ (—á–∏—Å–ª–æ —Å —Ç–æ—á–∫–æ–π –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ)
                                    if text and ('.' in text or text.replace('.', '').isdigit()):
                                        product_data['rating'] = text
                                        break
                                if product_data.get('rating'):
                                    break
                            except:
                                continue

                        if not product_data.get('rating'):
                            product_data['rating'] = ''

                    except Exception as e:
                        logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ —Ä–µ–π—Ç–∏–Ω–≥–∞: {e}")
                        product_data['rating'] = ''

                    # 6. –ö–û–õ–ò–ß–ï–°–¢–í–û –û–¢–ó–´–í–û–í
                    try:
                        reviews_selectors = [
                            ".p6b3_0_2-a4 span[style*='color:var(--textSecondary)']",  # –û—Ç–∑—ã–≤—ã
                            "span[style*='color:var(--textSecondary)']",  # –ü–æ —Ü–≤–µ—Ç—É
                            "//span[contains(text(), '–æ—Ç–∑—ã–≤')]"  # –ü–æ —Ç–µ–∫—Å—Ç—É
                        ]

                        for reviews_selector in reviews_selectors:
                            try:
                                if reviews_selector.startswith("//"):
                                    reviews_elems = card.find_elements(By.XPATH, reviews_selector)
                                else:
                                    reviews_elems = card.find_elements(By.CSS_SELECTOR, reviews_selector)

                                for elem in reviews_elems:
                                    text = elem.text.strip()
                                    if '–æ—Ç–∑—ã–≤' in text.lower():
                                        product_data['reviews_count'] = text
                                        break
                                if product_data.get('reviews_count'):
                                    break
                            except:
                                continue

                        if not product_data.get('reviews_count'):
                            product_data['reviews_count'] = ''

                    except Exception as e:
                        logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –æ—Ç–∑—ã–≤–æ–≤: {e}")
                        product_data['reviews_count'] = ''

                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–≤–∞—Ä —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ
                    if product_data.get('name'):
                        products.append(product_data)
                        logging.debug(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Ç–æ–≤–∞—Ä: {product_data['name'][:50]}...")

                except Exception as e:
                    logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–æ–≤–∞—Ä–∞: {e}")
                    continue

            logging.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–ø–∞—Ä—Å–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(products)}")
            return products

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Ç–æ–≤–∞—Ä–æ–≤: {str(e)}")
            return []

    def click_shop_button(self):
        """–ö–ª–∏–∫ –ø–æ –∫–Ω–æ–ø–∫–µ '–ú–∞–≥–∞–∑–∏–Ω' —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º–∏ –∏–∑ HTML"""
        try:
            logging.info("üõçÔ∏è –ò—â–µ–º –∫–Ω–æ–ø–∫—É '–ú–∞–≥–∞–∑–∏–Ω'...")

            # –û–°–ù–û–í–ù–´–ï –°–ï–õ–ï–ö–¢–û–†–´
            shop_selectors = [
                "div.b5_4_4-a0[title='–ú–∞–≥–∞–∑–∏–Ω']",  # –ü–æ title
                "div.b5_4_4-b0[title='–ú–∞–≥–∞–∑–∏–Ω']",  # –ü–æ title –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
                "//div[@title='–ú–∞–≥–∞–∑–∏–Ω' and contains(@class, 'b5_4_4-b0')]",  # XPath
                "div.b5_4_4-a0",  # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
                "//div[contains(@class, 'b5_4_4-b0') and text()='–ú–∞–≥–∞–∑–∏–Ω']"  # –ü–æ —Ç–µ–∫—Å—Ç—É
            ]

            for selector in shop_selectors:
                try:
                    if selector.startswith("//"):
                        elements = self.driver.find_elements(By.XPATH, selector)
                    else:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    logging.info(f"üîé –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–µ–ª–µ–∫—Ç–æ—Ä: {selector}, –Ω–∞–π–¥–µ–Ω–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(elements)}")

                    for element in elements:
                        try:
                            if element.is_displayed():
                                logging.info(f"üéØ –ù–∞—à–ª–∏ –∫–Ω–æ–ø–∫—É –º–∞–≥–∞–∑–∏–Ω–∞: '{element.text}'")

                                # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –∫–ª–∏–∫–∞
                                try:
                                    element.click()
                                except:
                                    self.driver.execute_script("arguments[0].click();", element)

                                time.sleep(3)
                                logging.info("‚úÖ –£—Å–ø–µ—à–Ω–æ –∫–ª–∏–∫–Ω—É–ª–∏ –Ω–∞ –∫–Ω–æ–ø–∫—É '–ú–∞–≥–∞–∑–∏–Ω'")
                                return True

                        except Exception as e:
                            logging.debug(f"‚ö†Ô∏è –≠–ª–µ–º–µ–Ω—Ç –Ω–µ –∫–ª–∏–∫–∞–±–µ–ª–µ–Ω: {e}")
                            continue

                except Exception as e:
                    logging.debug(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º {selector}: {e}")
                    continue

            logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏ –∫–ª–∏–∫–Ω—É—Ç—å –Ω–∞ –∫–Ω–æ–ø–∫—É '–ú–∞–≥–∞–∑–∏–Ω'")
            return False

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–ª–∏–∫–µ –Ω–∞ –∫–Ω–æ–ø–∫—É –º–∞–≥–∞–∑–∏–Ω–∞: {e}")
            return False

    def extract_legal_info_from_modal(self):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞ '–û –º–∞–≥–∞–∑–∏–Ω–µ'"""
        try:
            logging.info("‚öñÔ∏è –ò—â–µ–º –∏ –æ—Ç–∫—Ä—ã–≤–∞–µ–º –º–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –º–∞–≥–∞–∑–∏–Ω–µ...")

            legal_data = {}

            # –°–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞ (–¥–æ–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ)
            modal_button_selectors = [
                "//div[contains(@class, 'b5_4_4-a0')]//div[contains(text(), '–ú–∞–≥–∞–∑–∏–Ω')]",
                "//div[contains(@class, 'b5_4_4-b0') and contains(text(), '–ú–∞–≥–∞–∑–∏–Ω')]",
                "div.b5_4_4-a0[style*='background: var']"
            ]

            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∏ –∫–ª–∏–∫–Ω—É—Ç—å –Ω–∞ –∫–Ω–æ–ø–∫—É –æ—Ç–∫—Ä—ã—Ç–∏—è –º–æ–¥–∞–ª–∫–∏
            modal_opened = False
            for selector in modal_button_selectors:
                try:
                    if selector.startswith("//"):
                        elements = self.driver.find_elements(By.XPATH, selector)
                    else:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                    for element in elements:
                        if element.is_displayed():
                            logging.info(f"üéØ –ù–∞—à–ª–∏ –∫–Ω–æ–ø–∫—É –æ—Ç–∫—Ä—ã—Ç–∏—è –º–æ–¥–∞–ª–∫–∏: {selector}")
                            self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", element)
                            time.sleep(1)
                            self.driver.execute_script("arguments[0].click();", element)
                            time.sleep(3)
                            modal_opened = True
                            break
                    if modal_opened:
                        break
                except:
                    continue

            if not modal_opened:
                logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –º–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ")
                return legal_data

            # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.XPATH, "//div[contains(@class, 'b65_4_8-a')]"))
            )

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞
            modal_data = self.extract_all_modal_data()
            legal_data.update(modal_data)

            # –ó–∞–∫—Ä—ã–≤–∞–µ–º –º–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ
            self.close_modal()

            logging.info(f"‚úÖ –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∞: {legal_data}")
            return legal_data

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {e}")
            return {}

    def extract_all_modal_data(self):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞"""
        data = {}

        try:
            # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã (–ó–∞–∫–∞–∑—ã, –†–∞–±–æ—Ç–∞–µ—Ç —Å Ozon, –†–µ–π—Ç–∏–Ω–≥ –∏ —Ç.–¥.)
            cell_selectors = [
                "//div[contains(@class, 'b35_3_10-a9')]//span",  # –ù–∞–∑–≤–∞–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            ]

            # –ò—â–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ —Å –¥–∞–Ω–Ω—ã–º–∏
            rows = self.driver.find_elements(By.XPATH, "//div[contains(@class, 'b35_3_10-a')]")

            for row in rows:
                try:
                    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
                    param_name_element = row.find_element(By.XPATH, ".//div[contains(@class, 'b35_3_10-a9')]//span")
                    param_name = param_name_element.text.strip()

                    # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
                    value_element = row.find_element(By.XPATH, ".//div[contains(@class, 'b5_4_4-b0')]")
                    param_value = value_element.text.strip()

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–ª—è
                    if '–ó–∞–∫–∞–∑–æ–≤' in param_name:
                        data['–ó–∞–∫–∞–∑—ã'] = param_value
                    elif '–†–∞–±–æ—Ç–∞–µ—Ç —Å Ozon' in param_name:
                        data['–°—Ä–æ–∫_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏'] = param_value
                    elif '–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤' in param_name:
                        data['–†–µ–π—Ç–∏–Ω–≥'] = param_value
                    elif '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∑—ã–≤–æ–≤' in param_name:
                        data['–û—Ç–∑—ã–≤—ã'] = param_value

                except Exception as e:
                    continue

            # 2. –Æ—Ä–∏–¥–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (–û–ì–†–ù, –∞–¥—Ä–µ—Å –∏ —Ç.–¥.)
            try:
                legal_text_elements = self.driver.find_elements(
                    By.XPATH, "//div[contains(@class, 'bq03_0_2-a')]//span[contains(@class, 'tsBody400Small')]"
                )

                legal_text = ""
                for element in legal_text_elements:
                    legal_text += element.text.strip() + "\n"

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –û–ì–†–ù (13 —Ü–∏—Ñ—Ä)
                import re
                ogrn_match = re.search(r'\b\d{13}\b', legal_text)
                if ogrn_match:
                    data['–û–ì–†–ù'] = ogrn_match.group()

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —é—Ä–ª–∏—Ü–∞ (–ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞)
                lines = legal_text.split('\n')
                for line in lines:
                    if '–û–û–û' in line or '–ê–û' in line or '–ò–ü' in line:
                        data['–ù–∞–∑–≤–∞–Ω–∏–µ_—é—Ä_–ª–∏—Ü–∞'] = line.strip()
                        break

                data['–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π_–∞–¥—Ä–µ—Å'] = legal_text.strip()

            except Exception as e:
                logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —é—Ä–∏–¥–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é: {e}")

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ –º–æ–¥–∞–ª–∫–∏: {e}")

        return data

    def close_modal(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞"""
        try:
            close_selectors = [
                "button.b25_4_4-a0",  # –ö–Ω–æ–ø–∫–∞ "–ü–æ–Ω—è—Ç–Ω–æ"
                "button.b65_4_8-b1",  # –ö–Ω–æ–ø–∫–∞ –∑–∞–∫—Ä—ã—Ç–∏—è
                "//button[contains(., '–ü–æ–Ω—è—Ç–Ω–æ')]",
                "//button[contains(@class, 'b65_4_8-b1')]"
            ]

            for selector in close_selectors:
                try:
                    if selector.startswith("//"):
                        close_btn = self.driver.find_element(By.XPATH, selector)
                    else:
                        close_btn = self.driver.find_element(By.CSS_SELECTOR, selector)

                    if close_btn.is_displayed():
                        self.driver.execute_script("arguments[0].click();", close_btn)
                        time.sleep(2)
                        logging.info("‚úÖ –ú–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ –∑–∞–∫—Ä—ã—Ç–æ")
                        return True
                except:
                    continue

            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –∫–Ω–æ–ø–∫—É, –ø—Ä–æ–±—É–µ–º –∫–ª–∏–∫–Ω—É—Ç—å –≤–Ω–µ –º–æ–¥–∞–ª–∫–∏
            try:
                overlay = self.driver.find_element(By.CSS_SELECTOR, "div.b65_4_8-a0")
                self.driver.execute_script("arguments[0].click();", overlay)
                time.sleep(1)
            except:
                pass

        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–∫—Ä—ã—Ç—å –º–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ: {e}")

    def extract_shop_info(self):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¢–û–õ–¨–ö–û –Ω–∞–∑–≤–∞–Ω–∏—è –º–∞–≥–∞–∑–∏–Ω–∞ —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            data = {}

            #–ü–û–ò–°–ö –ù–ê–ó–í–ê–ù–ò–Ø –ú–ê–ì–ê–ó–ò–ù–ê
            try:
                main_page_name_selectors = [
                    "h1.seller-name",
                    ".seller-title",
                    "[data-widget='webSellerName']",
                    "//h1[contains(@class, 'seller')]",
                    "//div[contains(@class, 'seller-header')]//h1",
                    "//span[contains(@class, 'tsHeadline600Large')]",
                    ".bq03_0_2-a.bq03_0_2-a4.bq03_0_2-a5.h5n_19 span.tsHeadline600Large",
                    "//div[contains(@class, 'h5n_19')]//span"
                ]

                shop_name_found = False
                for selector in main_page_name_selectors:
                    try:
                        if selector.startswith("//"):
                            elements = self.driver.find_elements(By.XPATH, selector)
                        else:
                            elements = self.driver.find_elements(By.CSS_SELECTOR, selector)

                        for element in elements:
                            if element.is_displayed() and element.text.strip():
                                shop_name = element.text.strip()
                                if len(shop_name) > 2:
                                    data['–ù–∞–∑–≤–∞–Ω–∏–µ'] = shop_name
                                    logging.info(f"‚úÖ –ù–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞ –Ω–∞–π–¥–µ–Ω–æ –Ω–∞ –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {data['–ù–∞–∑–≤–∞–Ω–∏–µ']}")
                                    shop_name_found = True
                                    break

                        if shop_name_found:
                            break

                    except Exception as e:
                        continue

                if not shop_name_found:
                    logging.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –Ω–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞ —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã")
                    data['–ù–∞–∑–≤–∞–Ω–∏–µ'] = ''

            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –º–∞–≥–∞–∑–∏–Ω–∞: {e}")
                data['–ù–∞–∑–≤–∞–Ω–∏–µ'] = ''

            return data  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–∞–≥–∞–∑–∏–Ω–µ: {e}")
            return {'–ù–∞–∑–≤–∞–Ω–∏–µ': ''}

    def save_screenshot(self, seller_id, prefix=""):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
        try:
            screenshot_path = f"/app/screenshots/{prefix}{seller_id}_{int(time.time())}.png"
            self.driver.save_screenshot(screenshot_path)
            logging.info(f"üì∏ –°–æ—Ö—Ä–∞–Ω–µ–Ω —Å–∫—Ä–∏–Ω—à–æ—Ç: {screenshot_path}")
            return screenshot_path
        except Exception as e:
            logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç: {e}")
            return ""

    def parse_seller(self, seller_id):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø—Ä–æ–¥–∞–≤—Ü–∞"""
        url = f"https://www.ozon.ru/seller/{seller_id}"

        seller_data = {'URL': url}
        html_paths = []  # –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—É—Ç–µ–π –∫ HTML —Ñ–∞–π–ª–∞–º

        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
            self.driver.get(url)
            time.sleep(random.uniform(5, 8))

            # –°–û–•–†–ê–ù–Ø–ï–ú HTML –°–†–ê–ó–£ –ü–û–°–õ–ï –ó–ê–ì–†–£–ó–ö–ò
            main_html_path = self.save_html_page(seller_id, "main_")
            html_paths.append(main_html_path)

            # –°–û–•–†–ê–ù–Ø–ï–ú –°–ö–†–ò–ù–®–û–¢
            self.save_screenshot(seller_id, "loaded_")

            # –®–ê–ì 1: –ü–ï–†–í–û–ï –î–ï–õ–û - –ò–ó–í–õ–ï–ö–ê–ï–ú –ù–ê–ó–í–ê–ù–ò–ï –° –ì–õ–ê–í–ù–û–ô –°–¢–†–ê–ù–ò–¶–´
            try:
                shop_name_data = self.extract_shop_info()  # –¢–µ–ø–µ—Ä—å —ç—Ç–æ—Ç –º–µ—Ç–æ–¥ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¢–û–õ–¨–ö–û –Ω–∞–∑–≤–∞–Ω–∏–µ
                seller_data.update(shop_name_data)
                logging.info(f"‚úÖ –ù–∞–∑–≤–∞–Ω–∏–µ –º–∞–≥–∞–∑–∏–Ω–∞ –∏–∑–≤–ª–µ—á–µ–Ω–æ —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {seller_data.get('–ù–∞–∑–≤–∞–Ω–∏–µ', '')}")
            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –º–∞–≥–∞–∑–∏–Ω–∞: {e}")
                seller_data['–ù–∞–∑–≤–∞–Ω–∏–µ'] = ''

            # –®–ê–ì 2: –ü–∞—Ä—Å–∏–º —Ç–æ–≤–∞—Ä—ã —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            try:
                products = self.extract_products_from_main_page()
                seller_data['–ö–æ–ª-–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤_–Ω–∞_—Å—Ç—Ä–∞–Ω–∏—Ü–µ'] = len(products)
                seller_data['–¢–æ–≤–∞—Ä—ã_JSON'] = json.dumps(products, ensure_ascii=False)
                logging.info(f"‚úÖ –°–ø–∞—Ä—Å–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(products)}")
            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ —Ç–æ–≤–∞—Ä–æ–≤: {e}")
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç –ø—Ä–∏ –æ—à–∏–±–∫–µ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–æ–≤–∞—Ä–æ–≤
                self.save_screenshot(seller_id, "products_error_")
                seller_data['–ö–æ–ª-–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤_–Ω–∞_—Å—Ç—Ä–∞–Ω–∏—Ü–µ'] = 0
                seller_data['–¢–æ–≤–∞—Ä—ã_JSON'] = '[]'

            # –®–ê–ì 3: –ü–∞—Ä—Å–∏–º –º–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –í–°–ï–• –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            try:
                if self.click_shop_button():
                    # –°–û–•–†–ê–ù–Ø–ï–ú HTML –ü–û–°–õ–ï –ö–õ–ò–ö–ê –ù–ê –ú–ê–ì–ê–ó–ò–ù
                    shop_html_path = self.save_html_page(seller_id, "shop_")
                    html_paths.append(shop_html_path)

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –í–°–ï –¥–∞–Ω–Ω—ã–µ –∏–∑ –º–æ–¥–∞–ª–∫–∏
                    legal_info = self.extract_legal_info_from_modal()

                    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ –º–æ–¥–∞–ª–∫–∏ –ù–ï –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                    if '–ù–∞–∑–≤–∞–Ω–∏–µ' in legal_info:
                        logging.info(f"üîÅ –ù–∞–∑–≤–∞–Ω–∏–µ –∏–∑ –º–æ–¥–∞–ª–∫–∏ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç—Å—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã")
                        del legal_info['–ù–∞–∑–≤–∞–Ω–∏–µ']  # –£–¥–∞–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ –¥–∞–Ω–Ω—ã—Ö –º–æ–¥–∞–ª–∫–∏

                    seller_data.update(legal_info)  # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–π—Ç–∏–Ω–≥, –æ—Ç–∑—ã–≤—ã, —é—Ä–∏–¥–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ —Ç.–¥.
                    logging.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∏–∑ –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞ –∏–∑–≤–ª–µ—á–µ–Ω—ã: —Ä–µ–π—Ç–∏–Ω–≥, –æ—Ç–∑—ã–≤—ã, —é—Ä–∏–¥–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è")
                else:
                    logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –º–æ–¥–∞–ª–∫—É –¥–ª—è –ø—Ä–æ–¥–∞–≤—Ü–∞ {seller_id}")
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç –ø—Ä–∏ –Ω–µ—É–¥–∞—á–Ω–æ–º –∫–ª–∏–∫–µ
                    self.save_screenshot(seller_id, "shop_button_error_")
            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –º–æ–¥–∞–ª—å–Ω—ã–º –æ–∫–Ω–æ–º: {e}")
                self.save_screenshot(seller_id, "modal_error_")

            # –°–û–•–†–ê–ù–Ø–ï–ú –í–°–ï –ü–£–¢–ò –ö HTML –í –î–ê–ù–ù–´–ï
            seller_data['Html_–ø—É—Ç—å'] = "; ".join(html_paths)

            # –õ–æ–≥–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            logging.info(f"üìä –ò—Ç–æ–≥–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–¥–∞–≤—Ü–∞ {seller_id}:")
            logging.info(f"   - –ù–∞–∑–≤–∞–Ω–∏–µ: {seller_data.get('–ù–∞–∑–≤–∞–Ω–∏–µ', '–Ω–µ –Ω–∞–π–¥–µ–Ω–æ')}")
            logging.info(f"   - –†–µ–π—Ç–∏–Ω–≥: {seller_data.get('–†–µ–π—Ç–∏–Ω–≥', '–Ω–µ –Ω–∞–π–¥–µ–Ω')}")
            logging.info(f"   - –û—Ç–∑—ã–≤—ã: {seller_data.get('–û—Ç–∑—ã–≤—ã', '–Ω–µ –Ω–∞–π–¥–µ–Ω—ã')}")
            logging.info(f"   - –û–ì–†–ù: {seller_data.get('–û–ì–†–ù', '–Ω–µ –Ω–∞–π–¥–µ–Ω')}")
            logging.info(f"   - –¢–æ–≤–∞—Ä—ã: {seller_data.get('–ö–æ–ª-–≤–æ_—Ç–æ–≤–∞—Ä–æ–≤_–Ω–∞_—Å—Ç—Ä–∞–Ω–∏—Ü–µ', 0)} —à—Ç")

            self.save_to_csv(seller_data)
            logging.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –ø—Ä–æ–¥–∞–≤–µ—Ü {seller_id}")
            return seller_data

        except Exception as e:
            logging.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø—Ä–æ–¥–∞–≤—Ü–∞ {seller_id}: {e}")
            # –°–û–•–†–ê–ù–Ø–ï–ú –°–ö–†–ò–ù–®–û–¢ –ò HTML –ü–†–ò –õ–Æ–ë–û–ô –ö–†–ò–¢–ò–ß–ï–°–ö–û–ô –û–®–ò–ë–ö–ï
            self.save_screenshot(seller_id, "critical_error_")
            error_html_path = self.save_html_page(seller_id, "error_")
            seller_data['Html_–ø—É—Ç—å'] = error_html_path

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ, —á—Ç–æ —É—Å–ø–µ–ª–∏ —Å–æ–±—Ä–∞—Ç—å
            try:
                self.save_to_csv(seller_data)
            except:
                pass

            return None

    def close(self):
        """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ –¥—Ä–∞–π–≤–µ—Ä–∞ –∏ –æ—á–∏—Å—Ç–∫–∞"""
        if self.driver:
            try:
                self.driver.quit()
            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –¥—Ä–∞–π–≤–µ—Ä–∞: {e}")
            self.driver = None

        if self.chrome_temp_dir and os.path.exists(self.chrome_temp_dir):
            try:
                shutil.rmtree(self.chrome_temp_dir)
            except Exception as e:
                logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é: {e}")


def callback(ch, method, properties, body):
    seller_id = body.decode()

    logging.info(f"üéØ –ü–æ–ª—É—á–µ–Ω ID –ø—Ä–æ–¥–∞–≤—Ü–∞: {seller_id}")

    parser = None
    try:
        parser = OzonSellerParser()
        result = parser.parse_seller(seller_id)
        if result:
            logging.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –ø—Ä–æ–¥–∞–≤–µ—Ü {seller_id}")
        else:
            logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø—Ä–æ–¥–∞–≤—Ü–∞ {seller_id}")
        time.sleep(random.uniform(4, 7))
    except Exception as e:
        logging.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {seller_id}: {e}", exc_info=True)
    finally:
        if parser:
            parser.close()
    ch.basic_ack(delivery_tag=method.delivery_tag)


def start_consumer():
    while True:
        try:
            connection = pika.BlockingConnection(
                pika.ConnectionParameters(
                    host=os.getenv('RABBITMQ_HOST', 'rabbitmq'),
                    credentials=pika.PlainCredentials(
                        os.getenv('RABBITMQ_USER', 'admin'),
                        os.getenv('RABBITMQ_PASS', 'guest')
                    ),
                    heartbeat=600
                )
            )
            channel = connection.channel()
            channel.queue_declare(queue='seller_ids', durable=True)
            channel.basic_qos(prefetch_count=1)
            channel.basic_consume(queue='seller_ids', on_message_callback=callback)
            logging.info("üîÑ –û–∂–∏–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ RabbitMQ...")
            channel.start_consuming()
        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ RabbitMQ: {e}", exc_info=True)
            time.sleep(10)


if __name__ == "__main__":
    start_consumer()