import pandas as pd
import glob
import os
import sys
from datetime import datetime


def merge_csv_files():
    """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö CSV —Ñ–∞–π–ª–æ–≤ –≤ –æ–¥–∏–Ω —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–ª–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    data_dir = "/app/data"
    output_file = f"{data_dir}/combined_sellers_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"

    print("üîç –ü–æ–∏—Å–∫ CSV —Ñ–∞–π–ª–æ–≤...")

    # –ò—â–µ–º –≤—Å–µ CSV —Ñ–∞–π–ª—ã
    csv_files = glob.glob(f"{data_dir}/sellers_*.csv")

    if not csv_files:
        print("‚ùå CSV —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return

    print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(csv_files)}")

    # –ß–∏—Ç–∞–µ–º –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
    dataframes = []
    for file in csv_files:
        try:
            df = pd.read_csv(file, encoding='utf-8-sig')
            dataframes.append(df)
            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω: {os.path.basename(file)} ({len(df)} —Å—Ç—Ä–æ–∫)")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {file}: {e}")

    if dataframes:
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ DataFrame
        combined_df = pd.concat(dataframes, ignore_index=True)

        before_dedup = len(combined_df)
        print(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {before_dedup}")

        # üî• –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –°–æ—Ö—Ä–∞–Ω—è–µ–º –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ URL
        def get_data_completeness_score(row):
            """–û—Ü–µ–Ω–∏–≤–∞–µ–º –ø–æ–ª–Ω–æ—Ç—É –¥–∞–Ω–Ω—ã—Ö –≤ —Å—Ç—Ä–æ–∫–µ"""
            score = 0
            # –î–∞–µ–º –±–æ–ª—å—à–∏–π –≤–µ—Å –≤–∞–∂–Ω—ã–º –ø–æ–ª—è–º
            if pd.notna(row.get('–û–ì–†–ù')) and row.get('–û–ì–†–ù') != '':
                score += 10
            if pd.notna(row.get('–ù–∞–∑–≤–∞–Ω–∏–µ_—é—Ä_–ª–∏—Ü–∞')) and row.get('–ù–∞–∑–≤–∞–Ω–∏–µ_—é—Ä_–ª–∏—Ü–∞') != '':
                score += 8
            if pd.notna(row.get('–†–µ–π—Ç–∏–Ω–≥')) and row.get('–†–µ–π—Ç–∏–Ω–≥') != '':
                score += 5
            if pd.notna(row.get('–û—Ç–∑—ã–≤—ã')) and row.get('–û—Ç–∑—ã–≤—ã') != '':
                score += 5
            if pd.notna(row.get('–ó–∞–∫–∞–∑—ã')) and row.get('–ó–∞–∫–∞–∑—ã') != '':
                score += 5
            if pd.notna(row.get('–°—Ä–æ–∫_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏')) and row.get('–°—Ä–æ–∫_—Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏') != '':
                score += 5
            # –£—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö –ø–æ–ª–µ–π
            filled_fields = sum(1 for value in row.values if pd.notna(value) and value != '')
            score += filled_fields
            return score

        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–æ–ª–±–µ—Ü —Å –æ—Ü–µ–Ω–∫–æ–π –ø–æ–ª–Ω–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö
        combined_df['_completeness_score'] = combined_df.apply(get_data_completeness_score, axis=1)

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ–ª–Ω–æ—Ç–µ –¥–∞–Ω–Ω—ã—Ö (—Å–∞–º—ã–µ –ø–æ–ª–Ω—ã–µ –∑–∞–ø–∏—Å–∏ - –ø–µ—Ä–≤—ã–º–∏)
        combined_df = combined_df.sort_values('_completeness_score', ascending=False)

        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ URL, –æ—Å—Ç–∞–≤–ª—è—è —Å–∞–º—ã–µ –ø–æ–ª–Ω—ã–µ –∑–∞–ø–∏—Å–∏
        combined_df = combined_df.drop_duplicates(subset=['URL'], keep='first')

        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å—Ç–æ–ª–±–µ—Ü
        combined_df = combined_df.drop('_completeness_score', axis=1)

        after_dedup = len(combined_df)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        combined_df.to_csv(output_file, index=False, encoding='utf-8-sig')

        print(f"üéâ –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   - –ò—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(csv_files)}")
        print(f"   - –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–æ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {before_dedup}")
        print(f"   - –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {after_dedup}")
        print(f"   - –£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {before_dedup - after_dedup}")

        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö
        complete_records = len(combined_df[
                                   (combined_df['–û–ì–†–ù'].notna()) &
                                   (combined_df['–û–ì–†–ù'] != '') &
                                   (combined_df['–ù–∞–∑–≤–∞–Ω–∏–µ_—é—Ä_–ª–∏—Ü–∞'].notna()) &
                                   (combined_df['–ù–∞–∑–≤–∞–Ω–∏–µ_—é—Ä_–ª–∏—Ü–∞'] != '')
                                   ])
        print(f"   - –ó–∞–ø–∏—Å–µ–π —Å –ø–æ–ª–Ω—ã–º–∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏: {complete_records}")

        # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        stats_file = f"{data_dir}/merge_stats_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(stats_file, 'w', encoding='utf-8') as f:
            f.write("–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è CSV\n")
            f.write("=" * 40 + "\n")
            f.write(f"–î–∞—Ç–∞: {datetime.now()}\n")
            f.write(f"–ò—Å—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(csv_files)}\n")
            f.write(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –¥–æ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {before_dedup}\n")
            f.write(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {after_dedup}\n")
            f.write(f"–£–¥–∞–ª–µ–Ω–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {before_dedup - after_dedup}\n")
            f.write(f"–ó–∞–ø–∏—Å–µ–π —Å –ø–æ–ª–Ω—ã–º–∏ —é—Ä. –¥–∞–Ω–Ω—ã–º–∏: {complete_records}\n")
            f.write(f"–§–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {output_file}\n\n")
            f.write("–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:\n")
            for file in csv_files:
                f.write(f"- {os.path.basename(file)}\n")

        print(f"üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {stats_file}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        print("\nüîç –ü—Ä–∏–º–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
        sample_data = combined_df[['URL', '–ù–∞–∑–≤–∞–Ω–∏–µ', '–û–ì–†–ù', '–ù–∞–∑–≤–∞–Ω–∏–µ_—é—Ä_–ª–∏—Ü–∞']].head(3)
        for _, row in sample_data.iterrows():
            status = "‚úÖ –ü–û–õ–ù–´–ï –î–ê–ù–ù–´–ï" if pd.notna(row['–û–ì–†–ù']) and row['–û–ì–†–ù'] != '' else "‚ùå –ù–ï–ü–û–õ–ù–´–ï –î–ê–ù–ù–´–ï"
            print(f"   {status} | {row['URL']} | {row['–ù–∞–∑–≤–∞–Ω–∏–µ']}")

    else:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞")


if __name__ == "__main__":
    merge_csv_files()